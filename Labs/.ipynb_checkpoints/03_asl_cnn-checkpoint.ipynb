{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "weabkZTF3ZZM"
   },
   "source": [
    "<center><a href=\"https://www.nvidia.com/dli\"> <img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dz8YI6Fb3ZZN"
   },
   "source": [
    "# 3. Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8UWR4l4X3ZZN"
   },
   "source": [
    "In the previous section, we built and trained a simple model to classify ASL images. The model was able to learn how to correctly classify the training dataset with very high accuracy, but, it did not perform nearly as well on validation dataset. This behavior of not generalizing well to non-training data is called [overfitting](https://scikit-learn.org/stable/auto_examples/model_selection/plot_underfitting_overfitting.html), and in this section, we will introduce a popular kind of model called a [convolutional neural network](https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53) that is especially good for reading images and classifying them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GmRLS07k3ZZN"
   },
   "source": [
    "## 3.1 Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iuvwj_tr3ZZN"
   },
   "source": [
    "* Prep data specifically for a CNN\n",
    "* Create a more sophisticated CNN model, understanding a greater variety of model layers\n",
    "* Train a CNN model and observe its performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 221,
     "status": "ok",
     "timestamp": 1715240535370,
     "user": {
      "displayName": "Danielle Detering US",
      "userId": "15432464718872067879"
     },
     "user_tz": 420
    },
    "id": "9kMRTHEV2AFm",
    "outputId": "f1fb3858-e6a7-4906-ec7e-c4d34abcf013"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xEGukATl3ZZN"
   },
   "source": [
    "## 3.2 Loading and Preparing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Preparing Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-SyD7hID3ZZN"
   },
   "source": [
    "Let's begin by loading our DataFrames like we did in the previous lab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 3372,
     "status": "ok",
     "timestamp": 1715240541334,
     "user": {
      "displayName": "Danielle Detering US",
      "userId": "15432464718872067879"
     },
     "user_tz": 420
    },
    "id": "XMMgEMcc2Ehg"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../Data/asl_data/sign_mnist_train.csv\")\n",
    "valid_df = pd.read_csv(\"../Data/asl_data/sign_mnist_valid.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This ASL data is already flattened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[107, 118, 127, ..., 204, 203, 202],\n",
       "       [155, 157, 156, ..., 103, 135, 149],\n",
       "       [187, 188, 188, ..., 195, 194, 195],\n",
       "       [211, 211, 212, ..., 222, 229, 163],\n",
       "       [164, 167, 170, ..., 163, 164, 179]], shape=(5, 784))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df = train_df.head().copy()  # Grab the top 5 rows\n",
    "sample_df.pop('label')\n",
    "sample_x = sample_df.values\n",
    "sample_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 784)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this format, we don't have all the information about which pixels are near each other. Because of this, we can't apply convolutions that will detect features. Let's [reshape](https://numpy.org/doc/stable/reference/generated/numpy.reshape.html) our dataset so that they are in a 28x28 pixel format. This will allow our convolutions to associate groups of pixels and detect important features.\n",
    "\n",
    "Note that for the first convolutional layer of our model, we need to have not only the height and width of the image, but also the number of [color channels](https://www.photoshopessentials.com/essentials/rgb/). Our images are grayscale, so we'll just have 1 channel.\n",
    "\n",
    "That means that we need to convert the current shape `(5, 784)` to `(5, 1, 28, 28)`. With [NumPy](https://numpy.org/doc/stable/index.html) arrays, we can pass a `-1` for any dimension we wish to remain the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 1, 28, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG_HEIGHT = 28\n",
    "IMG_WIDTH = 28\n",
    "IMG_CHS = 1\n",
    "\n",
    "sample_x = sample_x.reshape(-1, IMG_CHS, IMG_HEIGHT, IMG_WIDTH)\n",
    "sample_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Create a Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add the steps above into our `MyDataset` class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 4 `FIXME`s in the class definition below. Can you replace them with the correct values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 173,
     "status": "ok",
     "timestamp": 1715240547901,
     "user": {
      "displayName": "Danielle Detering US",
      "userId": "15432464718872067879"
     },
     "user_tz": 420
    },
    "id": "tpzGOri32Klj"
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, base_df):\n",
    "        x_df = base_df.copy()  # Some operations below are in-place\n",
    "        y_df = x_df.pop('label')\n",
    "        x_df = x_df.values / 255  # Normalize values from 0 to 1\n",
    "        x_df = x_df.reshape(-1, IMG_CHS, IMG_WIDTH, IMG_HEIGHT)\n",
    "        self.xs = torch.tensor(x_df).float().to(device)\n",
    "        self.ys = torch.tensor(y_df).to(device)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.xs[idx]\n",
    "        y = self.ys[idx]\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.xs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click the `...` below for the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, base_df):\n",
    "        x_df = base_df.copy()  # Some operations below are in-place\n",
    "        y_df = x_df.pop('label')\n",
    "        x_df = x_df.values / 255  # Normalize values from 0 to 1\n",
    "        x_df = x_df.reshape(-1, IMG_CHS, IMG_WIDTH, IMG_HEIGHT)\n",
    "        self.xs = torch.tensor(x_df).float().to(device)\n",
    "        self.ys = torch.tensor(y_df).to(device)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.xs[idx]\n",
    "        y = self.ys[idx]\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.xs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 Create a DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's create the DataLoader from the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of these function calls is missing the `shuffle=True` argument. Can you remember which one it is and add it back in?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 1096,
     "status": "ok",
     "timestamp": 1715240550115,
     "user": {
      "displayName": "Danielle Detering US",
      "userId": "15432464718872067879"
     },
     "user_tz": 420
    },
    "id": "unf8Cz4WcK_M"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_data = MyDataset(train_df)\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "train_N = len(train_loader.dataset)\n",
    "\n",
    "valid_data = MyDataset(valid_df)\n",
    "valid_loader = DataLoader(valid_data, batch_size=BATCH_SIZE)\n",
    "valid_N = len(valid_loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click the `...` below for the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's grab a batch from the DataLoader to make sure it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1715240550382,
     "user": {
      "displayName": "Danielle Detering US",
      "userId": "15432464718872067879"
     },
     "user_tz": 420
    },
    "id": "Z4xylt03dz1W",
    "outputId": "80447d85-302d-4549-976b-f4c3ac0f0644"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[[0.3294, 0.3216, 0.2353,  ..., 0.6078, 0.6157, 0.6196],\n",
       "           [0.3412, 0.3255, 0.2431,  ..., 0.6039, 0.6157, 0.6196],\n",
       "           [0.3490, 0.3255, 0.2549,  ..., 0.6078, 0.6235, 0.6235],\n",
       "           ...,\n",
       "           [0.5373, 0.4510, 0.0902,  ..., 0.7294, 0.7333, 0.7373],\n",
       "           [0.5529, 0.4196, 0.0745,  ..., 0.7333, 0.7373, 0.7412],\n",
       "           [0.5647, 0.3961, 0.0745,  ..., 0.7373, 0.7373, 0.7451]]],\n",
       " \n",
       " \n",
       "         [[[0.6588, 0.6667, 0.6706,  ..., 0.6157, 0.6078, 0.6039],\n",
       "           [0.6627, 0.6667, 0.6745,  ..., 0.6196, 0.6078, 0.6078],\n",
       "           [0.6627, 0.6706, 0.6745,  ..., 0.6157, 0.6118, 0.6078],\n",
       "           ...,\n",
       "           [0.7373, 0.7529, 0.7569,  ..., 0.7176, 0.7059, 0.7020],\n",
       "           [0.7412, 0.7529, 0.7569,  ..., 0.7176, 0.7098, 0.7020],\n",
       "           [0.7412, 0.7529, 0.7608,  ..., 0.7176, 0.7137, 0.7059]]],\n",
       " \n",
       " \n",
       "         [[[0.6863, 0.6941, 0.6980,  ..., 0.6588, 0.6588, 0.6549],\n",
       "           [0.6941, 0.6980, 0.7059,  ..., 0.6706, 0.6667, 0.6627],\n",
       "           [0.7020, 0.7059, 0.7098,  ..., 0.6745, 0.6706, 0.6706],\n",
       "           ...,\n",
       "           [0.7961, 0.8078, 0.8980,  ..., 0.7843, 0.7804, 0.7765],\n",
       "           [0.5843, 0.7843, 0.8824,  ..., 0.7843, 0.7804, 0.7804],\n",
       "           [0.2471, 0.4902, 0.8000,  ..., 0.7882, 0.7843, 0.7843]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[0.6588, 0.6745, 0.6902,  ..., 0.7451, 0.7412, 0.7373],\n",
       "           [0.6667, 0.6902, 0.7020,  ..., 0.7529, 0.7490, 0.7490],\n",
       "           [0.6784, 0.6941, 0.7137,  ..., 0.7647, 0.7569, 0.7529],\n",
       "           ...,\n",
       "           [0.7882, 0.8078, 0.8314,  ..., 0.8941, 0.8824, 0.8745],\n",
       "           [0.7882, 0.8118, 0.8353,  ..., 0.9020, 0.8863, 0.8824],\n",
       "           [0.7922, 0.8157, 0.8314,  ..., 0.9020, 0.8980, 0.8902]]],\n",
       " \n",
       " \n",
       "         [[[0.5843, 0.6000, 0.6078,  ..., 0.6000, 0.5882, 0.5804],\n",
       "           [0.6039, 0.6078, 0.6196,  ..., 0.6118, 0.6000, 0.5961],\n",
       "           [0.6078, 0.6157, 0.6314,  ..., 0.6157, 0.6078, 0.6039],\n",
       "           ...,\n",
       "           [0.7373, 0.7451, 0.7569,  ..., 0.2941, 0.2314, 0.2078],\n",
       "           [0.7490, 0.7608, 0.7725,  ..., 0.3451, 0.2431, 0.1725],\n",
       "           [0.6353, 0.6549, 0.6706,  ..., 0.3686, 0.3176, 0.1922]]],\n",
       " \n",
       " \n",
       "         [[[0.4824, 0.5412, 0.5608,  ..., 0.7176, 0.7216, 0.7176],\n",
       "           [0.4902, 0.5451, 0.5647,  ..., 0.7216, 0.7255, 0.7216],\n",
       "           [0.4980, 0.5490, 0.5686,  ..., 0.7216, 0.7255, 0.7216],\n",
       "           ...,\n",
       "           [0.5804, 0.6039, 0.6235,  ..., 0.7961, 0.7961, 0.7961],\n",
       "           [0.5765, 0.6000, 0.6235,  ..., 0.8000, 0.7961, 0.7961],\n",
       "           [0.5765, 0.6039, 0.6235,  ..., 0.7961, 0.7961, 0.8000]]]]),\n",
       " tensor([21,  3, 17,  4,  4, 15, 11,  5, 12, 19, 16,  5, 22, 15,  6, 16,  8, 21,\n",
       "         19, 15,  7,  2, 14, 21, 20, 10, 13,  0, 15, 20,  3, 20])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks different, but let's check the `shape`s to be sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 205,
     "status": "ok",
     "timestamp": 1715240552534,
     "user": {
      "displayName": "Danielle Detering US",
      "userId": "15432464718872067879"
     },
     "user_tz": 420
    },
    "id": "vannMV7sd6R_",
    "outputId": "627858a2-a4ed-467c-cf82-2b7c1a01c13f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 28, 28])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 204,
     "status": "ok",
     "timestamp": 1715240553488,
     "user": {
      "displayName": "Danielle Detering US",
      "userId": "15432464718872067879"
     },
     "user_tz": 420
    },
    "id": "YHJgP3A7d9lu",
    "outputId": "4a40ceb8-039b-4517-de8a-bdcb814c4164"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6biSPXKJ3ZZP"
   },
   "source": [
    "## 3.3 Creating a Convolutional Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ppdkNb1A3ZZP"
   },
   "source": [
    "These days, many data scientists start their projects by borrowing model properties from a similar project. Assuming the problem is not totally unique, there's a great chance that people have created models that will perform well which are posted in online repositories like [TensorFlow Hub](https://www.tensorflow.org/hub) and the [NGC Catalog](https://ngc.nvidia.com/catalog/models). Today, we'll provide a model that will work well for this problem.\n",
    "\n",
    "<img src=\"../Images/cnn.png\" width=180 />\n",
    "\n",
    "We covered many of the different kinds of layers in the lecture, and we will go over them all here with links to their documentation. When in doubt, read the official documentation (or ask [Stack Overflow](https://stackoverflow.com/))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 202,
     "status": "ok",
     "timestamp": 1715240555184,
     "user": {
      "displayName": "Danielle Detering US",
      "userId": "15432464718872067879"
     },
     "user_tz": 420
    },
    "id": "p_bvGpMId_6q"
   },
   "outputs": [],
   "source": [
    "n_classes = 24\n",
    "kernel_size = 3\n",
    "flattened_img_size = 75 * 3 * 3\n",
    "\n",
    "model = nn.Sequential(\n",
    "    # First convolution\n",
    "    nn.Conv2d(IMG_CHS, 25, kernel_size, stride=1, padding=1),  # 25 x 28 x 28\n",
    "    nn.BatchNorm2d(25),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2, stride=2),  # 25 x 14 x 14\n",
    "    # Second convolution\n",
    "    nn.Conv2d(25, 50, kernel_size, stride=1, padding=1),  # 50 x 14 x 14\n",
    "    nn.BatchNorm2d(50),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(.2),\n",
    "    nn.MaxPool2d(2, stride=2),  # 50 x 7 x 7\n",
    "    # Third convolution\n",
    "    nn.Conv2d(50, 75, kernel_size, stride=1, padding=1),  # 75 x 7 x 7\n",
    "    nn.BatchNorm2d(75),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2, stride=2),  # 75 x 3 x 3\n",
    "    # Flatten to Dense\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(flattened_img_size, 512),\n",
    "    nn.Dropout(.3),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, n_classes)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8WsDr9gE3ZZP"
   },
   "source": [
    "### 3.3.1 [Conv2D](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8eHXRtWa3ZZP"
   },
   "source": [
    "<img src=\"images/conv2d.png\" width=300 />\n",
    "\n",
    "These are our 2D convolutional layers. Small kernels will go over the input image and detect features that are important for classification. Earlier convolutions in the model will detect simple features such as lines. Later convolutions will detect more complex features. Let's look at our first Conv2D layer:\n",
    "```Python\n",
    "nn.Conv2d(IMG_CHS, 25, kernel_size, stride=1, padding=1)\n",
    "```\n",
    "25 refers to the number of filters that will be learned. Even though `kernel_size = 3`, PyTorch will assume we want 3 x 3 filters. Stride refer to the step size that the filter will take as it passes over the image. Padding refers to whether the output image that's created from the filter will match the size of the input image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OiuMlsan3ZZQ"
   },
   "source": [
    "### 3.3.2 [BatchNormalization](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mp72aAnK3ZZQ"
   },
   "source": [
    "Like normalizing our inputs, batch normalization scales the values in the hidden layers to improve training. [Read more about it in detail here](https://blog.paperspace.com/busting-the-myths-about-batch-normalization/).\n",
    "\n",
    "There is a debate on best where to put the batch normalization layer. [This Stack Overflow post](https://stackoverflow.com/questions/39691902/ordering-of-batch-normalization-and-dropout) compiles many perspectives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "twarf_s63ZZQ"
   },
   "source": [
    "### 3.3.3 [MaxPool2D](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MoNIzZZW3ZZQ"
   },
   "source": [
    "<img src=\"images/maxpool2d.png\" width=300 />\n",
    "Max pooling takes an image and essentially shrinks it to a lower resolution. It does this to help the model be robust to translation (objects moving side to side), and also makes our model faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mzHlBRja3ZZQ"
   },
   "source": [
    "### 3.3.4 [Dropout](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FJjrPvkm3ZZQ"
   },
   "source": [
    "<img src=\"images/dropout.png\" width=360 />\n",
    "Dropout is a technique for preventing overfitting. Dropout randomly selects a subset of neurons and turns them off, so that they do not participate in forward or backward propagation in that particular pass. This helps to make sure that the network is robust and redundant, and does not rely on any one area to come up with answers.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NRYPkQPA3ZZQ"
   },
   "source": [
    "### 3.3.5 [Flatten](https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QuMt-DpZ3ZZQ"
   },
   "source": [
    "Flatten takes the output of one layer which is multidimensional, and flattens it into a one-dimensional array. The output is called a feature vector and will be connected to the final classification layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pSur4TGx3ZZQ"
   },
   "source": [
    "### 3.3.6 [Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PATqMedY3ZZQ"
   },
   "source": [
    "We have seen dense linear layers before in our earlier models. Our first dense layer (512 units) takes the feature vector as input and learns which features will contribute to a particular classification. The second dense layer (24 units) is the final classification layer that outputs our prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_opXKGWj3ZZQ"
   },
   "source": [
    "## 3.4 Summarizing the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eo6eRrp23ZZQ"
   },
   "source": [
    "This may feel like a lot of information, but don't worry. It's not critical that to understand everything right now in order to effectively train convolutional models. Most importantly we know that they can help with extracting useful information from images, and can be used in classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 200,
     "status": "ok",
     "timestamp": 1715240557183,
     "user": {
      "displayName": "Danielle Detering US",
      "userId": "15432464718872067879"
     },
     "user_tz": 420
    },
    "id": "2IAS92gZwcP3",
    "outputId": "56678948-aed0-4aa3-dde9-b8cecbaff44d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OptimizedModule(\n",
       "  (_orig_mod): Sequential(\n",
       "    (0): Conv2d(1, 25, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(25, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): Dropout(p=0.2, inplace=False)\n",
       "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (9): Conv2d(50, 75, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (10): BatchNorm2d(75, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): ReLU()\n",
       "    (12): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (13): Flatten(start_dim=1, end_dim=-1)\n",
       "    (14): Linear(in_features=675, out_features=512, bias=True)\n",
       "    (15): Dropout(p=0.3, inplace=False)\n",
       "    (16): ReLU()\n",
       "    (17): Linear(in_features=512, out_features=24, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.compile(model.to(device))\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the problem we are trying to solve is still the same (classifying ASL images), we will continue to use the same `loss_function` and `accuracy` metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 237,
     "status": "ok",
     "timestamp": 1715240559055,
     "user": {
      "displayName": "Danielle Detering US",
      "userId": "15432464718872067879"
     },
     "user_tz": 420
    },
    "id": "-BUIQ5COwsri"
   },
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1715240559790,
     "user": {
      "displayName": "Danielle Detering US",
      "userId": "15432464718872067879"
     },
     "user_tz": 420
    },
    "id": "SniWnvc5NSkA"
   },
   "outputs": [],
   "source": [
    "def get_batch_accuracy(output, y, N):\n",
    "    pred = output.argmax(dim=1, keepdim=True)\n",
    "    correct = pred.eq(y.view_as(pred)).sum().item()\n",
    "    return correct / N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OBgbUNDH3ZZR"
   },
   "source": [
    "### 3.5 Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tsS9zDKh3ZZR"
   },
   "source": [
    "Despite the very different model architecture, the training looks exactly the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the same `train` and `validate` functions as before, but they have been mixed up. Can you correctly name each function and replace the `FIXME`s?\n",
    "\n",
    "One of them should have `model.train` and the other should have `model.eval`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 214,
     "status": "ok",
     "timestamp": 1715240562885,
     "user": {
      "displayName": "Danielle Detering US",
      "userId": "15432464718872067879"
     },
     "user_tz": 420
    },
    "id": "e9R0vJA8NQUW"
   },
   "outputs": [],
   "source": [
    "def validate():\n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in valid_loader:\n",
    "            output = model(x)\n",
    "\n",
    "            loss += loss_function(output, y).item()\n",
    "            accuracy += get_batch_accuracy(output, y, valid_N)\n",
    "    print('Valid - Loss: {:.4f} Accuracy: {:.4f}'.format(loss, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 212,
     "status": "ok",
     "timestamp": 1715240561357,
     "user": {
      "displayName": "Danielle Detering US",
      "userId": "15432464718872067879"
     },
     "user_tz": 420
    },
    "id": "wr-X8QkVv9I7"
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "\n",
    "    model.train()\n",
    "    for x, y in train_loader:\n",
    "        output = model(x)\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss = loss_function(output, y)\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss += batch_loss.item()\n",
    "        accuracy += get_batch_accuracy(output, y, train_N)\n",
    "    print('Train - Loss: {:.4f} Accuracy: {:.4f}'.format(loss, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click the two `...`s below for the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "def validate():\n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in valid_loader:\n",
    "            output = model(x)\n",
    "\n",
    "            loss += loss_function(output, y).item()\n",
    "            accuracy += get_batch_accuracy(output, y, valid_N)\n",
    "    print('Valid - Loss: {:.4f} Accuracy: {:.4f}'.format(loss, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "def train():\n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "\n",
    "    model.train()\n",
    "    for x, y in train_loader:\n",
    "        output = model(x)\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss = loss_function(output, y)\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss += batch_loss.item()\n",
    "        accuracy += get_batch_accuracy(output, y, train_N)\n",
    "    print('Train - Loss: {:.4f} Accuracy: {:.4f}'.format(loss, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 720
    },
    "executionInfo": {
     "elapsed": 430665,
     "status": "error",
     "timestamp": 1715240995537,
     "user": {
      "displayName": "Danielle Detering US",
      "userId": "15432464718872067879"
     },
     "user_tz": 420
    },
    "id": "qOYsrlmUwyyI",
    "outputId": "ccbb497f-8f23-43c3-85c4-81f47c98728d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "ename": "InductorError",
     "evalue": "CppCompileError: C++ compile error\n\nCommand:\ncl /I C:/Program Files/WindowsApps/PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0/Include /I C:/Users/grsim/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0/LocalCache/local-packages/Python313/site-packages/torch/include /I C:/Users/grsim/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0/LocalCache/local-packages/Python313/site-packages/torch/include/torch/csrc/api/include /D TORCH_INDUCTOR_CPP_WRAPPER /D STANDALONE_TORCH_HEADER /D C10_USING_CUSTOM_GENERATED_MACROS /D CPU_CAPABILITY_AVX512 /DLL /MD /O2 /std:c++20 /wd4819 /wd4251 /wd4244 /wd4267 /wd4275 /wd4018 /wd4190 /wd4624 /wd4067 /wd4068 /EHsc /openmp /openmp:experimental C:/Users/grsim/AppData/Local/Temp/torchinductor_grsim/6g/c6gvgbhhmkzfnqez7el2fznzmlioke25zdsdxtrovbbklpyac7lg.cpp /arch:AVX512 /LD /FeC:/Users/grsim/AppData/Local/Temp/torchinductor_grsim/6g/c6gvgbhhmkzfnqez7el2fznzmlioke25zdsdxtrovbbklpyac7lg.pyd /link /LIBPATH:C:/Program Files/WindowsApps/PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0/libs /LIBPATH:C:/Users/grsim/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0/LocalCache/local-packages/Python313/site-packages/torch/lib torch.lib torch_cpu.lib torch_python.lib sleef.lib\n\nOutput:\nMicrosoft (R) C/C++ Optimizing Compiler Version 19.43.34810 for x64\r\nCopyright (C) Microsoft Corporation.  All rights reserved.\r\n\r\ncl : Command line warning D9025 : overriding '/openmp' with '/openmp:experimental'\r\nc6gvgbhhmkzfnqez7el2fznzmlioke25zdsdxtrovbbklpyac7lg.cpp\r\nC:/Users/grsim/AppData/Local/Temp/torchinductor_grsim/6g/c6gvgbhhmkzfnqez7el2fznzmlioke25zdsdxtrovbbklpyac7lg.cpp(121): error C2374: 'tmp_acc0_arr': redefinition; multiple initialization\r\nC:/Users/grsim/AppData/Local/Temp/torchinductor_grsim/6g/c6gvgbhhmkzfnqez7el2fznzmlioke25zdsdxtrovbbklpyac7lg.cpp(102): note: see declaration of 'tmp_acc0_arr'\r\nC:/Users/grsim/AppData/Local/Temp/torchinductor_grsim/6g/c6gvgbhhmkzfnqez7el2fznzmlioke25zdsdxtrovbbklpyac7lg.cpp(121): error C2086: 'std::unique_ptr<float [],std::default_delete<float []>> tmp_acc0_arr': redefinition\r\nC:/Users/grsim/AppData/Local/Temp/torchinductor_grsim/6g/c6gvgbhhmkzfnqez7el2fznzmlioke25zdsdxtrovbbklpyac7lg.cpp(102): note: see declaration of 'tmp_acc0_arr'\r\nC:/Users/grsim/AppData/Local/Temp/torchinductor_grsim/6g/c6gvgbhhmkzfnqez7el2fznzmlioke25zdsdxtrovbbklpyac7lg.cpp(121): error C2371: 'tmp_acc0_arr': redefinition; different basic types\r\nC:/Users/grsim/AppData/Local/Temp/torchinductor_grsim/6g/c6gvgbhhmkzfnqez7el2fznzmlioke25zdsdxtrovbbklpyac7lg.cpp(131): error C2374: 'tmp_acc1_arr': redefinition; multiple initialization\r\nC:/Users/grsim/AppData/Local/Temp/torchinductor_grsim/6g/c6gvgbhhmkzfnqez7el2fznzmlioke25zdsdxtrovbbklpyac7lg.cpp(107): note: see declaration of 'tmp_acc1_arr'\r\nC:/Users/grsim/AppData/Local/Temp/torchinductor_grsim/6g/c6gvgbhhmkzfnqez7el2fznzmlioke25zdsdxtrovbbklpyac7lg.cpp(131): error C2086: 'std::unique_ptr<float [],std::default_delete<float []>> tmp_acc1_arr': redefinition\r\nC:/Users/grsim/AppData/Local/Temp/torchinductor_grsim/6g/c6gvgbhhmkzfnqez7el2fznzmlioke25zdsdxtrovbbklpyac7lg.cpp(107): note: see declaration of 'tmp_acc1_arr'\r\nC:/Users/grsim/AppData/Local/Temp/torchinductor_grsim/6g/c6gvgbhhmkzfnqez7el2fznzmlioke25zdsdxtrovbbklpyac7lg.cpp(131): error C2371: 'tmp_acc1_arr': redefinition; different basic types\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInductorError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[32m      4\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mEpoch: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m'\u001b[39m.format(epoch))\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     validate()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      8\u001b[39m optimizer.zero_grad()\n\u001b[32m      9\u001b[39m batch_loss = loss_function(output, y)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43mbatch_loss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m optimizer.step()\n\u001b[32m     13\u001b[39m loss += batch_loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\_tensor.py:648\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    640\u001b[39m         Tensor.backward,\n\u001b[32m    641\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    646\u001b[39m         inputs=inputs,\n\u001b[32m    647\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\autograd\\__init__.py:353\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    348\u001b[39m     retain_graph = create_graph\n\u001b[32m    350\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\autograd\\graph.py:824\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    823\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    825\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    827\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    828\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\autograd\\function.py:307\u001b[39m, in \u001b[36mBackwardCFunction.apply\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    301\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    302\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mImplementing both \u001b[39m\u001b[33m'\u001b[39m\u001b[33mbackward\u001b[39m\u001b[33m'\u001b[39m\u001b[33m and \u001b[39m\u001b[33m'\u001b[39m\u001b[33mvjp\u001b[39m\u001b[33m'\u001b[39m\u001b[33m for a custom \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    303\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFunction is not allowed. You should only implement one \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    304\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mof them.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    305\u001b[39m     )\n\u001b[32m    306\u001b[39m user_fn = vjp_fn \u001b[38;5;28;01mif\u001b[39;00m vjp_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Function.vjp \u001b[38;5;28;01melse\u001b[39;00m backward_fn\n\u001b[32m--> \u001b[39m\u001b[32m307\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43muser_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\_functorch\\_aot_autograd\\runtime_wrappers.py:2111\u001b[39m, in \u001b[36mAOTDispatchAutograd.post_compile.<locals>.CompiledFunction.backward\u001b[39m\u001b[34m(ctx, *flat_args)\u001b[39m\n\u001b[32m   2109\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m CompiledFunction._double_backward(ctx, impl_fn, all_args)\n\u001b[32m   2110\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2111\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\_functorch\\_aot_autograd\\runtime_wrappers.py:2097\u001b[39m, in \u001b[36mAOTDispatchAutograd.post_compile.<locals>.CompiledFunction.backward.<locals>.impl_fn\u001b[39m\u001b[34m(double_ctx)\u001b[39m\n\u001b[32m   2096\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mimpl_fn\u001b[39m(double_ctx=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m-> \u001b[39m\u001b[32m2097\u001b[39m     out = \u001b[43mCompiledFunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_backward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2098\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _backward_epilogue_functional(\n\u001b[32m   2099\u001b[39m         CompiledFunction.metadata,\n\u001b[32m   2100\u001b[39m         CompiledFunction.maybe_subclass_metadata,\n\u001b[32m   2101\u001b[39m         out,\n\u001b[32m   2102\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\_functorch\\_aot_autograd\\runtime_wrappers.py:2186\u001b[39m, in \u001b[36mAOTDispatchAutograd.post_compile.<locals>.CompiledFunction._backward_impl\u001b[39m\u001b[34m(ctx, all_args)\u001b[39m\n\u001b[32m   2175\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m tracing(saved_context), compile_context(\n\u001b[32m   2176\u001b[39m     saved_compile_context\n\u001b[32m   2177\u001b[39m ), context(), track_graph_compiling(\n\u001b[32m   (...)\u001b[39m\u001b[32m   2183\u001b[39m     dynamo_compile_column_us=\u001b[33m\"\u001b[39m\u001b[33mbackward_cumulative_compile_time_us\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2184\u001b[39m ):\n\u001b[32m   2185\u001b[39m     CompileEventLogger.compilation_metric(is_forward=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2186\u001b[39m     CompiledFunction.compiled_bw = \u001b[43maot_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbw_compiler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2187\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbw_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplaceholder_list\u001b[49m\n\u001b[32m   2188\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2189\u001b[39m     \u001b[38;5;66;03m# Maybe save cache entry\u001b[39;00m\n\u001b[32m   2190\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m try_save_cache_entry \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2191\u001b[39m         \u001b[38;5;66;03m# CompiledFunction.metadata\u001b[39;00m\n\u001b[32m   2192\u001b[39m         \u001b[38;5;66;03m# CompiledFunction.maybe_subclass_metadata\u001b[39;00m\n\u001b[32m   2193\u001b[39m         \u001b[38;5;66;03m# bw_module\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\_functorch\\aot_autograd.py:479\u001b[39m, in \u001b[36mSerializableAOTDispatchCompiler.__call__\u001b[39m\u001b[34m(self, gm, example_inputs)\u001b[39m\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\n\u001b[32m    475\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    476\u001b[39m     gm: torch.fx.GraphModule,\n\u001b[32m    477\u001b[39m     example_inputs: Sequence[InputType],\n\u001b[32m    478\u001b[39m ) -> OutputCode:\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompiler_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\_dynamo\\backends\\common.py:72\u001b[39m, in \u001b[36mAotAutograd.__call__.<locals>.wrap_bw_compiler.<locals>._wrapped_bw_compiler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_wrapped_bw_compiler\u001b[39m(*args, **kwargs):\n\u001b[32m     71\u001b[39m     \u001b[38;5;66;03m# stop TorchDynamo from trying to compile our generated backwards pass\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m disable(\u001b[43mdisable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbw_compiler_fn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\_dynamo\\eval_frame.py:838\u001b[39m, in \u001b[36mDisableContext.__call__.<locals>._fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    836\u001b[39m _maybe_set_eval_frame(_callback_from_stance(\u001b[38;5;28mself\u001b[39m.callback))\n\u001b[32m    837\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m838\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    839\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    840\u001b[39m     set_eval_frame(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\_utils_internal.py:97\u001b[39m, in \u001b[36mcompile_time_strobelight_meta.<locals>.compile_time_strobelight_meta_inner.<locals>.wrapper_function\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     94\u001b[39m \u001b[38;5;66;03m# This is not needed but we have it here to avoid having profile_compile_time\u001b[39;00m\n\u001b[32m     95\u001b[39m \u001b[38;5;66;03m# in stack traces when profiling is not enabled.\u001b[39;00m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m StrobelightCompileTimeProfiler.enabled:\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m StrobelightCompileTimeProfiler.profile_compile_time(\n\u001b[32m    100\u001b[39m     function, phase_name, *args, **kwargs\n\u001b[32m    101\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\_inductor\\compile_fx.py:2014\u001b[39m, in \u001b[36mcompile_fx.<locals>.bw_compiler\u001b[39m\u001b[34m(gm, example_inputs)\u001b[39m\n\u001b[32m   2008\u001b[39m fixed = count_tangents(gm)\n\u001b[32m   2009\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m (\n\u001b[32m   2010\u001b[39m     config.patch(get_cpp_wrapper_config())\n\u001b[32m   2011\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m config.cpp_wrapper\n\u001b[32m   2012\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m contextlib.nullcontext()\n\u001b[32m   2013\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m2014\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2015\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2016\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2017\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstatic_input_idxs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfixed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2018\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcudagraphs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcudagraphs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2019\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_backward\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   2020\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgraph_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgraph_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2021\u001b[39m \u001b[43m        \u001b[49m\u001b[43mboxed_forward_device_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforward_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2022\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\_inductor\\compile_fx.py:628\u001b[39m, in \u001b[36mcompile_fx_inner\u001b[39m\u001b[34m(gm, example_inputs, **kwargs)\u001b[39m\n\u001b[32m    623\u001b[39m stack.enter_context(DebugContext())\n\u001b[32m    624\u001b[39m CompileEventLogger.pt2_compile(\n\u001b[32m    625\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33minductor_compile\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    626\u001b[39m     is_backward=kwargs[\u001b[33m\"\u001b[39m\u001b[33mis_backward\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    627\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m628\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrap_compiler_debug\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_compile_fx_inner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompiler_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minductor\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    629\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    630\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    631\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    632\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\_dynamo\\repro\\after_aot.py:124\u001b[39m, in \u001b[36mwrap_compiler_debug.<locals>.debug_wrapper\u001b[39m\u001b[34m(gm, example_inputs, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m config.repro_after \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33mdynamo\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33maot\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    122\u001b[39m     \u001b[38;5;66;03m# Call the compiler_fn - which is either aot_autograd or inductor\u001b[39;00m\n\u001b[32m    123\u001b[39m     \u001b[38;5;66;03m# with fake inputs\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m     inner_compiled_fn = \u001b[43mcompiler_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    126\u001b[39m     \u001b[38;5;66;03m# TODO: Failures here are troublesome because no real inputs,\u001b[39;00m\n\u001b[32m    127\u001b[39m     \u001b[38;5;66;03m# need a different serialization strategy\u001b[39;00m\n\u001b[32m    128\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m config.repro_after == \u001b[33m\"\u001b[39m\u001b[33maot\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\_inductor\\compile_fx.py:760\u001b[39m, in \u001b[36m_compile_fx_inner\u001b[39m\u001b[34m(gm, example_inputs, **graph_kwargs)\u001b[39m\n\u001b[32m    758\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m    759\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m760\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m InductorError(e, currentframe()).with_traceback(\n\u001b[32m    761\u001b[39m         e.__traceback__\n\u001b[32m    762\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    763\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    764\u001b[39m     TritonBundler.end_compile()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\_inductor\\compile_fx.py:745\u001b[39m, in \u001b[36m_compile_fx_inner\u001b[39m\u001b[34m(gm, example_inputs, **graph_kwargs)\u001b[39m\n\u001b[32m    743\u001b[39m TritonBundler.begin_compile()\n\u001b[32m    744\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m745\u001b[39m     mb_compiled_graph = \u001b[43mfx_codegen_and_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    746\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_to_check\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgraph_kwargs\u001b[49m\n\u001b[32m    747\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    748\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m mb_compiled_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    749\u001b[39m     mb_compiled_graph._time_taken_ns = time.time_ns() - start_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\_inductor\\compile_fx.py:1295\u001b[39m, in \u001b[36mfx_codegen_and_compile\u001b[39m\u001b[34m(gm, example_inputs, inputs_to_check, **graph_kwargs)\u001b[39m\n\u001b[32m   1291\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompile_fx_subproc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _SubprocessFxCompile\n\u001b[32m   1293\u001b[39m     scheme = _SubprocessFxCompile()\n\u001b[32m-> \u001b[39m\u001b[32m1295\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mscheme\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcodegen_and_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_to_check\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\_inductor\\compile_fx.py:1197\u001b[39m, in \u001b[36m_InProcessFxCompile.codegen_and_compile\u001b[39m\u001b[34m(self, gm, example_inputs, inputs_to_check, graph_kwargs)\u001b[39m\n\u001b[32m   1184\u001b[39m             compiled_fn = AotCodeCompiler.compile(\n\u001b[32m   1185\u001b[39m                 graph,\n\u001b[32m   1186\u001b[39m                 wrapper_code.value,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1194\u001b[39m                 ],\n\u001b[32m   1195\u001b[39m             )\n\u001b[32m   1196\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1197\u001b[39m         compiled_fn = \u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile_to_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.call\n\u001b[32m   1199\u001b[39m num_bytes, nodes_num_elem, node_runtimes = graph.count_bytes()\n\u001b[32m   1200\u001b[39m metrics.num_bytes_accessed += num_bytes\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\_inductor\\graph.py:2083\u001b[39m, in \u001b[36mGraphLowering.compile_to_module\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2076\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompile_to_module\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> ModuleType:\n\u001b[32m   2077\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m dynamo_timed(\n\u001b[32m   2078\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mGraphLowering.compile_to_module\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2079\u001b[39m         phase_name=\u001b[33m\"\u001b[39m\u001b[33mcode_gen\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2080\u001b[39m         log_pt2_compile_event=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m   2081\u001b[39m         dynamo_compile_column_us=\u001b[33m\"\u001b[39m\u001b[33minductor_code_gen_cumulative_compile_time_us\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2082\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m2083\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_compile_to_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\_inductor\\graph.py:2130\u001b[39m, in \u001b[36mGraphLowering._compile_to_module\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2124\u001b[39m     trace_structured(\n\u001b[32m   2125\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33minductor_output_code\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2126\u001b[39m         \u001b[38;5;28;01mlambda\u001b[39;00m: {\u001b[33m\"\u001b[39m\u001b[33mfilename\u001b[39m\u001b[33m\"\u001b[39m: path},\n\u001b[32m   2127\u001b[39m         payload_fn=\u001b[38;5;28;01mlambda\u001b[39;00m: wrapper_code.value,\n\u001b[32m   2128\u001b[39m     )\n\u001b[32m   2129\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m dynamo_timed(\u001b[33m\"\u001b[39m\u001b[33mPyCodeCache.load_by_key_path\u001b[39m\u001b[33m\"\u001b[39m, log_pt2_compile_event=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m-> \u001b[39m\u001b[32m2130\u001b[39m     mod = \u001b[43mPyCodeCache\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_by_key_path\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2131\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2132\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2133\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlinemap\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlinemap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   2134\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconstants\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtorchbind_constants\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2135\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2136\u001b[39m \u001b[38;5;28mself\u001b[39m.cache_key = key\n\u001b[32m   2137\u001b[39m \u001b[38;5;28mself\u001b[39m.cache_path = path\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\_inductor\\codecache.py:2747\u001b[39m, in \u001b[36mPyCodeCache.load_by_key_path\u001b[39m\u001b[34m(cls, key, path, linemap, attrs)\u001b[39m\n\u001b[32m   2744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m linemap \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2745\u001b[39m     linemap = []\n\u001b[32m-> \u001b[39m\u001b[32m2747\u001b[39m mod = \u001b[43m_reload_python_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2749\u001b[39m \u001b[38;5;66;03m# unzip into separate lines/nodes lists\u001b[39;00m\n\u001b[32m   2750\u001b[39m \u001b[38;5;28mcls\u001b[39m.linemaps[path] = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(*linemap))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\_inductor\\runtime\\compile_tasks.py:36\u001b[39m, in \u001b[36m_reload_python_module\u001b[39m\u001b[34m(key, path)\u001b[39m\n\u001b[32m     34\u001b[39m mod.\u001b[34m__file__\u001b[39m = path\n\u001b[32m     35\u001b[39m mod.key = key  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m \u001b[43mexec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmod\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__dict__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmod\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__dict__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m sys.modules[mod.\u001b[34m__name__\u001b[39m] = mod\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m mod\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Temp\\torchinductor_grsim\\ap\\cap4dhvxu3rflkcjp2bfkjxhu4zdianmdluggo55n6nmyuwflmyo.py:617\u001b[39m\n\u001b[32m     64\u001b[39m cpp_fused_convolution_backward_max_pool2d_with_indices_max_pool2d_with_indices_backward_native_batch_norm_backward_threshold_backward_1 = async_compile.cpp_pybinding([\u001b[33m'\u001b[39m\u001b[33mfloat*\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mconst int8_t*\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mconst float*\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mconst float*\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mconst float*\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mconst float*\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mconst float*\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mfloat*\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mfloat*\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mfloat*\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mfloat*\u001b[39m\u001b[33m'\u001b[39m], \u001b[33m'''\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[33m#include \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mC:/Users/grsim/AppData/Local/Temp/torchinductor_grsim/pi/cpicxudqmdsjh5cm4klbtbrvy2cxwr7whxl3md2zzdjdf3orvfdf.h\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[33mextern \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mC\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m __declspec(dllexport) void kernel(float* in_out_ptr0,\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    329\u001b[39m \u001b[33m}\u001b[39m\n\u001b[32m    330\u001b[39m \u001b[33m'''\u001b[39m)\n\u001b[32m    333\u001b[39m cpp_fused__native_batch_norm_legit_functional_convolution_backward_max_pool2d_with_indices_max_pool2d_with_indices_backward_native_batch_norm_backward_native_dropout_backward_relu_threshold_backward_2 = async_compile.cpp_pybinding([\u001b[33m'\u001b[39m\u001b[33mfloat*\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mconst int8_t*\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mconst float*\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mconst float*\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mconst float*\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mconst float*\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mconst float*\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mconst float*\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mconst bool*\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mfloat*\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mfloat*\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mfloat*\u001b[39m\u001b[33m'\u001b[39m], \u001b[33m'''\u001b[39m\n\u001b[32m    334\u001b[39m \u001b[33m#include \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mC:/Users/grsim/AppData/Local/Temp/torchinductor_grsim/pi/cpicxudqmdsjh5cm4klbtbrvy2cxwr7whxl3md2zzdjdf3orvfdf.h\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    335\u001b[39m \u001b[33mextern \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mC\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m __declspec(dllexport) void kernel(float* in_out_ptr0,\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    613\u001b[39m \u001b[33m}\u001b[39m\n\u001b[32m    614\u001b[39m \u001b[33m'''\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m617\u001b[39m cpp_fused_convolution_backward_max_pool2d_with_indices_max_pool2d_with_indices_backward_native_batch_norm_backward_threshold_backward_3 = \u001b[43masync_compile\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcpp_pybinding\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfloat*\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mconst int8_t*\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mconst float*\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mconst float*\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mconst float*\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mconst float*\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mconst float*\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfloat*\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfloat*\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfloat*\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfloat*\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'''\u001b[39;49m\n\u001b[32m    618\u001b[39m \u001b[33;43m#include \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mC:/Users/grsim/AppData/Local/Temp/torchinductor_grsim/pi/cpicxudqmdsjh5cm4klbtbrvy2cxwr7whxl3md2zzdjdf3orvfdf.h\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m    619\u001b[39m \u001b[33;43mextern \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mC\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m __declspec(dllexport) void kernel(float* in_out_ptr0,\u001b[39;49m\n\u001b[32m    620\u001b[39m \u001b[33;43m                       const int8_t* in_ptr0,\u001b[39;49m\n\u001b[32m    621\u001b[39m \u001b[33;43m                       const float* in_ptr1,\u001b[39;49m\n\u001b[32m    622\u001b[39m \u001b[33;43m                       const float* in_ptr3,\u001b[39;49m\n\u001b[32m    623\u001b[39m \u001b[33;43m                       const float* in_ptr4,\u001b[39;49m\n\u001b[32m    624\u001b[39m \u001b[33;43m                       const float* in_ptr5,\u001b[39;49m\n\u001b[32m    625\u001b[39m \u001b[33;43m                       const float* in_ptr6,\u001b[39;49m\n\u001b[32m    626\u001b[39m \u001b[33;43m                       float* out_ptr0,\u001b[39;49m\n\u001b[32m    627\u001b[39m \u001b[33;43m                       float* out_ptr1,\u001b[39;49m\n\u001b[32m    628\u001b[39m \u001b[33;43m                       float* out_ptr2,\u001b[39;49m\n\u001b[32m    629\u001b[39m \u001b[33;43m                       float* out_ptr3)\u001b[39;49m\n\u001b[32m    630\u001b[39m \u001b[33;43m{\u001b[39;49m\n\u001b[32m    631\u001b[39m \u001b[33;43m    auto in_ptr2 = in_out_ptr0;\u001b[39;49m\n\u001b[32m    632\u001b[39m \u001b[33;43m    #pragma omp parallel num_threads(8)\u001b[39;49m\n\u001b[32m    633\u001b[39m \u001b[33;43m    \u001b[39;49m\u001b[33;43m{\u001b[39;49m\n\u001b[32m    634\u001b[39m \u001b[33;43m        int tid = omp_get_thread_num();\u001b[39;49m\n\u001b[32m    635\u001b[39m \u001b[33;43m        \u001b[39;49m\u001b[33;43m{\u001b[39;49m\n\u001b[32m    636\u001b[39m \u001b[33;43m            #pragma omp for\u001b[39;49m\n\u001b[32m    637\u001b[39m \u001b[33;43m            for(int64_t x0=static_cast<int64_t>(0LL); x0<static_cast<int64_t>(32LL); x0+=static_cast<int64_t>(1LL))\u001b[39;49m\n\u001b[32m    638\u001b[39m \u001b[33;43m            \u001b[39;49m\u001b[33;43m{\u001b[39;49m\n\u001b[32m    639\u001b[39m \u001b[33;43m                for(int64_t x1=static_cast<int64_t>(0LL); x1<static_cast<int64_t>(28LL); x1+=static_cast<int64_t>(1LL))\u001b[39;49m\n\u001b[32m    640\u001b[39m \u001b[33;43m                \u001b[39;49m\u001b[33;43m{\u001b[39;49m\n\u001b[32m    641\u001b[39m \u001b[33;43m                    for(int64_t x2=static_cast<int64_t>(0LL); x2<static_cast<int64_t>(28LL); x2+=static_cast<int64_t>(1LL))\u001b[39;49m\n\u001b[32m    642\u001b[39m \u001b[33;43m                    \u001b[39;49m\u001b[33;43m{\u001b[39;49m\n\u001b[32m    643\u001b[39m \u001b[33;43m                        for(int64_t x3=static_cast<int64_t>(0LL); x3<static_cast<int64_t>(25LL); x3+=static_cast<int64_t>(16LL))\u001b[39;49m\n\u001b[32m    644\u001b[39m \u001b[33;43m                        \u001b[39;49m\u001b[33;43m{\u001b[39;49m\n\u001b[32m    645\u001b[39m \u001b[33;43m                            \u001b[39;49m\u001b[33;43m{\u001b[39;49m\n\u001b[32m    646\u001b[39m \u001b[33;43m                                if(C10_LIKELY(x3 >= static_cast<int64_t>(0) && x3 < static_cast<int64_t>(16LL)))\u001b[39;49m\n\u001b[32m    647\u001b[39m \u001b[33;43m                                \u001b[39;49m\u001b[33;43m{\u001b[39;49m\n\u001b[32m    648\u001b[39m \u001b[33;43m                                    auto tmp0 = at::vec::Vectorized<int8_t>::loadu(in_ptr0 + static_cast<int64_t>(x3 + 25LL*std::min(static_cast<int64_t>(std::max(static_cast<int64_t>(0LL), static_cast<int64_t>(c10::div_floor_integer(static_cast<int64_t>(x2), static_cast<int64_t>(2LL))))), static_cast<int64_t>((-1LL) + std::min(static_cast<int64_t>(14LL), static_cast<int64_t>(1LL + (c10::div_floor_integer(static_cast<int64_t>(x2), static_cast<int64_t>(2LL))))))) + 350LL*std::min(static_cast<int64_t>(std::max(static_cast<int64_t>(0LL), static_cast<int64_t>(c10::div_floor_integer(static_cast<int64_t>(x1), static_cast<int64_t>(2LL))))), static_cast<int64_t>((-1LL) + std::min(static_cast<int64_t>(14LL), static_cast<int64_t>(1LL + (c10::div_floor_integer(static_cast<int64_t>(x1), static_cast<int64_t>(2LL))))))) + 4900LL*x0), static_cast<int64_t>(16));\u001b[39;49m\n\u001b[32m    649\u001b[39m \u001b[33;43m                                    auto tmp21 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<int64_t>(x3 + 25LL*std::min(static_cast<int64_t>(std::max(static_cast<int64_t>(0LL), static_cast<int64_t>(c10::div_floor_integer(static_cast<int64_t>(x2), static_cast<int64_t>(2LL))))), static_cast<int64_t>((-1LL) + std::min(static_cast<int64_t>(14LL), static_cast<int64_t>(1LL + (c10::div_floor_integer(static_cast<int64_t>(x2), static_cast<int64_t>(2LL))))))) + 350LL*std::min(static_cast<int64_t>(std::max(static_cast<int64_t>(0LL), static_cast<int64_t>(c10::div_floor_integer(static_cast<int64_t>(x1), static_cast<int64_t>(2LL))))), static_cast<int64_t>((-1LL) + std::min(static_cast<int64_t>(14LL), static_cast<int64_t>(1LL + (c10::div_floor_integer(static_cast<int64_t>(x1), static_cast<int64_t>(2LL))))))) + 4900LL*x0), static_cast<int64_t>(16));\u001b[39;49m\n\u001b[32m    650\u001b[39m \u001b[33;43m                                    auto tmp1 = static_cast<int32_t>(2);\u001b[39;49m\n\u001b[32m    651\u001b[39m \u001b[33;43m                                    auto tmp2 = at::vec::convert<int32_t>(tmp0);\u001b[39;49m\n\u001b[32m    652\u001b[39m \u001b[33;43m                                    auto tmp3 = at::vec::Vectorized<int32_t>(tmp1);\u001b[39;49m\n\u001b[32m    653\u001b[39m \u001b[33;43m                                    auto tmp4 = decltype(tmp2)::blendv(tmp2 / tmp3, tmp2 / tmp3 - decltype(tmp2)(1), (tmp2 \u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43m tmp3 != decltype(tmp2)(0)) & ((tmp2 < decltype(tmp2)(0)) != (tmp3 < decltype(tmp2)(0))));\u001b[39;49m\n\u001b[32m    654\u001b[39m \u001b[33;43m                                    auto tmp5 = tmp4 * tmp3;\u001b[39;49m\n\u001b[32m    655\u001b[39m \u001b[33;43m                                    auto tmp6 = tmp2 - tmp5;\u001b[39;49m\n\u001b[32m    656\u001b[39m \u001b[33;43m                                    auto tmp7 = 2LL*std::min(static_cast<int64_t>(std::max(static_cast<int64_t>(0LL), static_cast<int64_t>(c10::div_floor_integer(static_cast<int64_t>(x1), static_cast<int64_t>(2LL))))), static_cast<int64_t>((-1LL) + std::min(static_cast<int64_t>(14LL), static_cast<int64_t>(1LL + (c10::div_floor_integer(static_cast<int64_t>(x1), static_cast<int64_t>(2LL)))))));\u001b[39;49m\n\u001b[32m    657\u001b[39m \u001b[33;43m                                    auto tmp8 = c10::convert<int64_t>(tmp7);\u001b[39;49m\n\u001b[32m    658\u001b[39m \u001b[33;43m                                    auto tmp9 = at::vec::convert<int64_t,2,int32_t,1>(tmp4);\u001b[39;49m\n\u001b[32m    659\u001b[39m \u001b[33;43m                                    auto tmp10 = at::vec::VectorizedN<int64_t,2>(tmp8);\u001b[39;49m\n\u001b[32m    660\u001b[39m \u001b[33;43m                                    auto tmp11 = tmp10 + tmp9;\u001b[39;49m\n\u001b[32m    661\u001b[39m \u001b[33;43m                                    auto tmp12 = 2LL*std::min(static_cast<int64_t>(std::max(static_cast<int64_t>(0LL), static_cast<int64_t>(c10::div_floor_integer(static_cast<int64_t>(x2), static_cast<int64_t>(2LL))))), static_cast<int64_t>((-1LL) + std::min(static_cast<int64_t>(14LL), static_cast<int64_t>(1LL + (c10::div_floor_integer(static_cast<int64_t>(x2), static_cast<int64_t>(2LL)))))));\u001b[39;49m\n\u001b[32m    662\u001b[39m \u001b[33;43m                                    auto tmp13 = c10::convert<int64_t>(tmp12);\u001b[39;49m\n\u001b[32m    663\u001b[39m \u001b[33;43m                                    auto tmp14 = at::vec::convert<int64_t,2,int32_t,1>(tmp6);\u001b[39;49m\n\u001b[32m    664\u001b[39m \u001b[33;43m                                    auto tmp15 = at::vec::VectorizedN<int64_t,2>(tmp13);\u001b[39;49m\n\u001b[32m    665\u001b[39m \u001b[33;43m                                    auto tmp16 = tmp15 + tmp14;\u001b[39;49m\n\u001b[32m    666\u001b[39m \u001b[33;43m                                    auto tmp17 = static_cast<int64_t>(28);\u001b[39;49m\n\u001b[32m    667\u001b[39m \u001b[33;43m                                    auto tmp18 = at::vec::VectorizedN<int64_t,2>(tmp17);\u001b[39;49m\n\u001b[32m    668\u001b[39m \u001b[33;43m                                    auto tmp19 = tmp11 * tmp18;\u001b[39;49m\n\u001b[32m    669\u001b[39m \u001b[33;43m                                    auto tmp20 = tmp19 + tmp16;\u001b[39;49m\n\u001b[32m    670\u001b[39m \u001b[33;43m                                    auto tmp22 = x2 + 28LL*x1;\u001b[39;49m\n\u001b[32m    671\u001b[39m \u001b[33;43m                                    auto tmp23 = c10::convert<int32_t>(tmp22);\u001b[39;49m\n\u001b[32m    672\u001b[39m \u001b[33;43m                                    auto tmp24 = c10::convert<int64_t>(tmp23);\u001b[39;49m\n\u001b[32m    673\u001b[39m \u001b[33;43m                                    auto tmp25 = at::vec::VectorizedN<int64_t,2>(tmp24);\u001b[39;49m\n\u001b[32m    674\u001b[39m \u001b[33;43m                                    auto tmp26 = at::vec::VecMask<int64_t,2>(tmp20 == tmp25);\u001b[39;49m\n\u001b[32m    675\u001b[39m \u001b[33;43m                                    auto tmp27 = static_cast<float>(0.0);\u001b[39;49m\n\u001b[32m    676\u001b[39m \u001b[33;43m                                    auto tmp28 = at::vec::Vectorized<float>(tmp27);\u001b[39;49m\n\u001b[32m    677\u001b[39m \u001b[33;43m                                    auto tmp29 = decltype(tmp21)::blendv(tmp28, tmp21, tmp26.template cast<float,1>());\u001b[39;49m\n\u001b[32m    678\u001b[39m \u001b[33;43m                                    tmp29.store(out_ptr0 + static_cast<int64_t>(x3 + 25LL*x2 + 700LL*x1 + 19600LL*x0));\u001b[39;49m\n\u001b[32m    679\u001b[39m \u001b[33;43m                                }\u001b[39;49m\n\u001b[32m    680\u001b[39m \u001b[33;43m                                if(C10_UNLIKELY(x3 >= static_cast<int64_t>(16LL) && x3 < static_cast<int64_t>(25LL)))\u001b[39;49m\n\u001b[32m    681\u001b[39m \u001b[33;43m                                \u001b[39;49m\u001b[33;43m{\u001b[39;49m\n\u001b[32m    682\u001b[39m \u001b[33;43m                                    for (int64_t x3_tail = static_cast<int64_t>(16LL);x3_tail < static_cast<int64_t>(25LL); x3_tail++)\u001b[39;49m\n\u001b[32m    683\u001b[39m \u001b[33;43m                                    \u001b[39;49m\u001b[33;43m{\u001b[39;49m\n\u001b[32m    684\u001b[39m \u001b[33;43m                                        auto tmp0 = in_ptr0[static_cast<int64_t>(x3_tail + 25LL*std::min(static_cast<int64_t>(std::max(static_cast<int64_t>(0LL), static_cast<int64_t>(c10::div_floor_integer(static_cast<int64_t>(x2), static_cast<int64_t>(2LL))))), static_cast<int64_t>((-1LL) + std::min(static_cast<int64_t>(14LL), static_cast<int64_t>(1LL + (c10::div_floor_integer(static_cast<int64_t>(x2), static_cast<int64_t>(2LL))))))) + 350LL*std::min(static_cast<int64_t>(std::max(static_cast<int64_t>(0LL), static_cast<int64_t>(c10::div_floor_integer(static_cast<int64_t>(x1), static_cast<int64_t>(2LL))))), static_cast<int64_t>((-1LL) + std::min(static_cast<int64_t>(14LL), static_cast<int64_t>(1LL + (c10::div_floor_integer(static_cast<int64_t>(x1), static_cast<int64_t>(2LL))))))) + 4900LL*x0)];\u001b[39;49m\n\u001b[32m    685\u001b[39m \u001b[33;43m                                        auto tmp14 = in_ptr1[static_cast<int64_t>(x3_tail + 25LL*std::min(static_cast<int64_t>(std::max(static_cast<int64_t>(0LL), static_cast<int64_t>(c10::div_floor_integer(static_cast<int64_t>(x2), static_cast<int64_t>(2LL))))), static_cast<int64_t>((-1LL) + std::min(static_cast<int64_t>(14LL), static_cast<int64_t>(1LL + (c10::div_floor_integer(static_cast<int64_t>(x2), static_cast<int64_t>(2LL))))))) + 350LL*std::min(static_cast<int64_t>(std::max(static_cast<int64_t>(0LL), static_cast<int64_t>(c10::div_floor_integer(static_cast<int64_t>(x1), static_cast<int64_t>(2LL))))), static_cast<int64_t>((-1LL) + std::min(static_cast<int64_t>(14LL), static_cast<int64_t>(1LL + (c10::div_floor_integer(static_cast<int64_t>(x1), static_cast<int64_t>(2LL))))))) + 4900LL*x0)];\u001b[39;49m\n\u001b[32m    686\u001b[39m \u001b[33;43m                                        auto tmp1 = static_cast<int32_t>(2);\u001b[39;49m\n\u001b[32m    687\u001b[39m \u001b[33;43m                                        auto tmp2 = ((tmp0 < 0) != (tmp1 < 0) ? (tmp0 \u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43m tmp1 != 0 ? tmp0 / tmp1 - 1 : tmp0 / tmp1) : tmp0 / tmp1);\u001b[39;49m\n\u001b[32m    688\u001b[39m \u001b[33;43m                                        auto tmp3 = decltype(tmp2)(tmp2 * tmp1);\u001b[39;49m\n\u001b[32m    689\u001b[39m \u001b[33;43m                                        auto tmp4 = decltype(tmp0)(tmp0 - tmp3);\u001b[39;49m\n\u001b[32m    690\u001b[39m \u001b[33;43m                                        auto tmp5 = 2LL*std::min(static_cast<int64_t>(std::max(static_cast<int64_t>(0LL), static_cast<int64_t>(c10::div_floor_integer(static_cast<int64_t>(x1), static_cast<int64_t>(2LL))))), static_cast<int64_t>((-1LL) + std::min(static_cast<int64_t>(14LL), static_cast<int64_t>(1LL + (c10::div_floor_integer(static_cast<int64_t>(x1), static_cast<int64_t>(2LL)))))));\u001b[39;49m\n\u001b[32m    691\u001b[39m \u001b[33;43m                                        auto tmp6 = c10::convert<int64_t>(tmp5);\u001b[39;49m\n\u001b[32m    692\u001b[39m \u001b[33;43m                                        auto tmp7 = decltype(tmp6)(tmp6 + tmp2);\u001b[39;49m\n\u001b[32m    693\u001b[39m \u001b[33;43m                                        auto tmp8 = 2LL*std::min(static_cast<int64_t>(std::max(static_cast<int64_t>(0LL), static_cast<int64_t>(c10::div_floor_integer(static_cast<int64_t>(x2), static_cast<int64_t>(2LL))))), static_cast<int64_t>((-1LL) + std::min(static_cast<int64_t>(14LL), static_cast<int64_t>(1LL + (c10::div_floor_integer(static_cast<int64_t>(x2), static_cast<int64_t>(2LL)))))));\u001b[39;49m\n\u001b[32m    694\u001b[39m \u001b[33;43m                                        auto tmp9 = c10::convert<int64_t>(tmp8);\u001b[39;49m\n\u001b[32m    695\u001b[39m \u001b[33;43m                                        auto tmp10 = decltype(tmp9)(tmp9 + tmp4);\u001b[39;49m\n\u001b[32m    696\u001b[39m \u001b[33;43m                                        auto tmp11 = static_cast<int64_t>(28);\u001b[39;49m\n\u001b[32m    697\u001b[39m \u001b[33;43m                                        auto tmp12 = decltype(tmp7)(tmp7 * tmp11);\u001b[39;49m\n\u001b[32m    698\u001b[39m \u001b[33;43m                                        auto tmp13 = decltype(tmp12)(tmp12 + tmp10);\u001b[39;49m\n\u001b[32m    699\u001b[39m \u001b[33;43m                                        auto tmp15 = x2 + 28LL*x1;\u001b[39;49m\n\u001b[32m    700\u001b[39m \u001b[33;43m                                        auto tmp16 = c10::convert<int32_t>(tmp15);\u001b[39;49m\n\u001b[32m    701\u001b[39m \u001b[33;43m                                        auto tmp17 = tmp13 == tmp16;\u001b[39;49m\n\u001b[32m    702\u001b[39m \u001b[33;43m                                        auto tmp18 = static_cast<float>(0.0);\u001b[39;49m\n\u001b[32m    703\u001b[39m \u001b[33;43m                                        auto tmp19 = tmp17 ? tmp14 : tmp18;\u001b[39;49m\n\u001b[32m    704\u001b[39m \u001b[33;43m                                        out_ptr0[static_cast<int64_t>(x3_tail + 25LL*x2 + 700LL*x1 + 19600LL*x0)] = tmp19;\u001b[39;49m\n\u001b[32m    705\u001b[39m \u001b[33;43m                                    }\u001b[39;49m\n\u001b[32m    706\u001b[39m \u001b[33;43m                                }\u001b[39;49m\n\u001b[32m    707\u001b[39m \u001b[33;43m                            }\u001b[39;49m\n\u001b[32m    708\u001b[39m \u001b[33;43m                        }\u001b[39;49m\n\u001b[32m    709\u001b[39m \u001b[33;43m                    }\u001b[39;49m\n\u001b[32m    710\u001b[39m \u001b[33;43m                }\u001b[39;49m\n\u001b[32m    711\u001b[39m \u001b[33;43m            }\u001b[39;49m\n\u001b[32m    712\u001b[39m \u001b[33;43m        }\u001b[39;49m\n\u001b[32m    713\u001b[39m \u001b[33;43m    }\u001b[39;49m\n\u001b[32m    714\u001b[39m \u001b[33;43m    \u001b[39;49m\u001b[33;43m{\u001b[39;49m\n\u001b[32m    715\u001b[39m \u001b[33;43m        for(int64_t x0=static_cast<int64_t>(0LL); x0<static_cast<int64_t>(25LL); x0+=static_cast<int64_t>(16LL))\u001b[39;49m\n\u001b[32m    716\u001b[39m \u001b[33;43m        \u001b[39;49m\u001b[33;43m{\u001b[39;49m\n\u001b[32m    717\u001b[39m \u001b[33;43m            \u001b[39;49m\u001b[33;43m{\u001b[39;49m\n\u001b[32m    718\u001b[39m \u001b[33;43m                auto tmp_acc0_arr = std::make_unique<float[]>(16);\u001b[39;49m\n\u001b[32m    719\u001b[39m \u001b[33;43m                for (int i = 0; i < 16; i++)\u001b[39;49m\n\u001b[32m    720\u001b[39m \u001b[33;43m                \u001b[39;49m\u001b[33;43m{\u001b[39;49m\n\u001b[32m    721\u001b[39m \u001b[33;43m                    tmp_acc0_arr[i] = 0;\u001b[39;49m\n\u001b[32m    722\u001b[39m \u001b[33;43m                }\u001b[39;49m\n\u001b[32m    723\u001b[39m \u001b[33;43m                auto tmp_acc1_arr = std::make_unique<float[]>(16);\u001b[39;49m\n\u001b[32m    724\u001b[39m \u001b[33;43m                for (int i = 0; i < 16; i++)\u001b[39;49m\n\u001b[32m    725\u001b[39m \u001b[33;43m                \u001b[39;49m\u001b[33;43m{\u001b[39;49m\n\u001b[32m    726\u001b[39m \u001b[33;43m                    tmp_acc1_arr[i] = 0;\u001b[39;49m\n\u001b[32m    727\u001b[39m \u001b[33;43m                }\u001b[39;49m\n\u001b[32m    728\u001b[39m \u001b[33;43m                float tmp_acc0 = 0;\u001b[39;49m\n\u001b[32m    729\u001b[39m \u001b[33;43m                at::vec::Vectorized<float> tmp_acc0_vec = at::vec::Vectorized<float>(0);\u001b[39;49m\n\u001b[32m    730\u001b[39m \u001b[33;43m                float tmp_acc1 = 0;\u001b[39;49m\n\u001b[32m    731\u001b[39m \u001b[33;43m                at::vec::Vectorized<float> tmp_acc1_vec = at::vec::Vectorized<float>(0);\u001b[39;49m\n\u001b[32m    732\u001b[39m \u001b[33;43m                auto tmp_acc0_vec_arr = std::make_unique<at::vec::Vectorized<float>[]>(8);\u001b[39;49m\n\u001b[32m    733\u001b[39m \u001b[33;43m                for (int i = 0; i < 8; i++)\u001b[39;49m\n\u001b[32m    734\u001b[39m \u001b[33;43m                \u001b[39;49m\u001b[33;43m{\u001b[39;49m\n\u001b[32m    735\u001b[39m \u001b[33;43m                    tmp_acc0_vec_arr[i] = at::vec::Vectorized<float>(0);\u001b[39;49m\n\u001b[32m    736\u001b[39m \u001b[33;43m                }\u001b[39;49m\n\u001b[32m    737\u001b[39m \u001b[33;43m                auto tmp_acc0_arr = std::make_unique<float[]>(8);\u001b[39;49m\n\u001b[32m    738\u001b[39m \u001b[33;43m                for (int i = 0; i < 8; i++)\u001b[39;49m\n\u001b[32m    739\u001b[39m \u001b[33;43m                \u001b[39;49m\u001b[33;43m{\u001b[39;49m\n\u001b[32m    740\u001b[39m \u001b[33;43m                    tmp_acc0_arr[i] = 0;\u001b[39;49m\n\u001b[32m    741\u001b[39m \u001b[33;43m                }\u001b[39;49m\n\u001b[32m    742\u001b[39m \u001b[33;43m                auto tmp_acc1_vec_arr = std::make_unique<at::vec::Vectorized<float>[]>(8);\u001b[39;49m\n\u001b[32m    743\u001b[39m \u001b[33;43m                for (int i = 0; i < 8; i++)\u001b[39;49m\n\u001b[32m    744\u001b[39m \u001b[33;43m                \u001b[39;49m\u001b[33;43m{\u001b[39;49m\n\u001b[32m    745\u001b[39m \u001b[33;43m                    tmp_acc1_vec_arr[i] = at::vec::Vectorized<float>(0);\u001b[39;49m\n\u001b[32m    746\u001b[39m \u001b[33;43m                }\u001b[39;49m\n\u001b[32m    747\u001b[39m \u001b[33;43m                auto tmp_acc1_arr = std::make_unique<float[]>(8);\u001b[39;49m\n\u001b[32m    748\u001b[39m \u001b[33;43m                for (int i = 0; i < 8; i++)\u001b[39;49m\n\u001b[32m    749\u001b[39m \u001b[33;43m                \u001b[39;49m\u001b[33;43m{\u001b[39;49m\n\u001b[32m    750\u001b[39m \u001b[33;43m                    tmp_acc1_arr[i] = 0;\u001b[39;49m\n\u001b[32m    751\u001b[39m \u001b[33;43m                }\u001b[39;49m\n\u001b[32m    752\u001b[39m \u001b[33;43m                #pragma omp parallel num_threads(8)\u001b[39;49m\n\u001b[32m    753\u001b[39m \u001b[33;43m                \u001b[39;49m\u001b[33;43m{\u001b[39;49m\n\u001b[32m    754\u001b[39m \u001b[33;43m                    int tid = omp_get_thread_num();\u001b[39;49m\n\u001b[32m    755\u001b[39m \u001b[33;43m                    at::vec::Vectorized<float> tmp_acc0_vec_local = at::vec::Vectorized<float>(0);\u001b[39;49m\n\u001b[32m    756\u001b[39m \u001b[33;43m                    float tmp_acc0_local = 0;\u001b[39;49m\n\u001b[32m    757\u001b[39m \u001b[33;43m                    at::vec::Vectorized<float> tmp_acc1_vec_local = at::vec::Vectorized<float>(0);\u001b[39;49m\n\u001b[32m    758\u001b[39m \u001b[33;43m                    float tmp_acc1_local = 0;\u001b[39;49m\n\u001b[32m    759\u001b[39m \u001b[33;43m                    #pragma omp for\u001b[39;49m\n\u001b[32m    760\u001b[39m \u001b[33;43m                    for(int64_t x1=static_cast<int64_t>(0LL); x1<static_cast<int64_t>(25088LL); x1+=static_cast<int64_t>(1LL))\u001b[39;49m\n\u001b[32m    761\u001b[39m \u001b[33;43m                    \u001b[39;49m\u001b[33;43m{\u001b[39;49m\n\u001b[32m    762\u001b[39m \u001b[33;43m                        \u001b[39;49m\u001b[33;43m{\u001b[39;49m\n\u001b[32m    763\u001b[39m \u001b[33;43m                            if(C10_LIKELY(x0 >= static_cast<int64_t>(0) && x0 < static_cast<int64_t>(16LL)))\u001b[39;49m\n\u001b[32m    764\u001b[39m \u001b[33;43m                            \u001b[39;49m\u001b[33;43m{\u001b[39;49m\n\u001b[32m    765\u001b[39m \u001b[33;43m                                auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<int64_t>(x0 + 25LL*x1), static_cast<int64_t>(16));\u001b[39;49m\n\u001b[32m    766\u001b[39m \u001b[33;43m                                auto tmp4 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<int64_t>(x0 + 25LL*x1), static_cast<int64_t>(16));\u001b[39;49m\n\u001b[32m    767\u001b[39m \u001b[33;43m                                auto tmp6 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<int64_t>(x0 + 25LL*x1), static_cast<int64_t>(16));\u001b[39;49m\n\u001b[32m    768\u001b[39m \u001b[33;43m                                auto tmp7 = at::vec::Vectorized<float>::loadu(in_ptr4 + static_cast<int64_t>(x0), static_cast<int64_t>(16));\u001b[39;49m\n\u001b[32m    769\u001b[39m \u001b[33;43m                                auto tmp1 = static_cast<float>(0.0);\u001b[39;49m\n\u001b[32m    770\u001b[39m \u001b[33;43m                                auto tmp2 = at::vec::Vectorized<float>(tmp1);\u001b[39;49m\n\u001b[32m    771\u001b[39m \u001b[33;43m                                auto tmp3 = at::vec::VecMask<float,1>(tmp0 <= tmp2);\u001b[39;49m\n\u001b[32m    772\u001b[39m \u001b[33;43m                                auto tmp5 = decltype(tmp2)::blendv(tmp4, tmp2, tmp3.template cast<float,1>());\u001b[39;49m\n\u001b[32m    773\u001b[39m \u001b[33;43m                                auto tmp8 = tmp6 - tmp7;\u001b[39;49m\n\u001b[32m    774\u001b[39m \u001b[33;43m                                auto tmp9 = tmp5 * tmp8;\u001b[39;49m\n\u001b[32m    775\u001b[39m \u001b[33;43m                                tmp_acc0_vec_local = tmp_acc0_vec_local + tmp5;\u001b[39;49m\n\u001b[32m    776\u001b[39m \u001b[33;43m                                tmp_acc1_vec_local = tmp_acc1_vec_local + tmp9;\u001b[39;49m\n\u001b[32m    777\u001b[39m \u001b[33;43m                            }\u001b[39;49m\n\u001b[32m    778\u001b[39m \u001b[33;43m                            if(C10_UNLIKELY(x0 >= static_cast<int64_t>(16LL) && x0 < static_cast<int64_t>(25LL)))\u001b[39;49m\n\u001b[32m    779\u001b[39m \u001b[33;43m                            \u001b[39;49m\u001b[33;43m{\u001b[39;49m\n\u001b[32m    780\u001b[39m \u001b[33;43m                                for (int64_t x0_tail = static_cast<int64_t>(16LL);x0_tail < static_cast<int64_t>(25LL); x0_tail++)\u001b[39;49m\n\u001b[32m    781\u001b[39m \u001b[33;43m                                \u001b[39;49m\u001b[33;43m{\u001b[39;49m\n\u001b[32m    782\u001b[39m \u001b[33;43m                                    auto tmp0 = in_ptr2[static_cast<int64_t>(x0_tail + 25LL*x1)];\u001b[39;49m\n\u001b[32m    783\u001b[39m \u001b[33;43m                                    auto tmp3 = out_ptr0[static_cast<int64_t>(x0_tail + 25LL*x1)];\u001b[39;49m\n\u001b[32m    784\u001b[39m \u001b[33;43m                                    auto tmp5 = in_ptr3[static_cast<int64_t>(x0_tail + 25LL*x1)];\u001b[39;49m\n\u001b[32m    785\u001b[39m \u001b[33;43m                                    auto tmp6 = in_ptr4[static_cast<int64_t>(x0_tail)];\u001b[39;49m\n\u001b[32m    786\u001b[39m \u001b[33;43m                                    auto tmp1 = static_cast<float>(0.0);\u001b[39;49m\n\u001b[32m    787\u001b[39m \u001b[33;43m                                    auto tmp2 = tmp0 <= tmp1;\u001b[39;49m\n\u001b[32m    788\u001b[39m \u001b[33;43m                                    auto tmp4 = tmp2 ? tmp1 : tmp3;\u001b[39;49m\n\u001b[32m    789\u001b[39m \u001b[33;43m                                    auto tmp7 = decltype(tmp5)(tmp5 - tmp6);\u001b[39;49m\n\u001b[32m    790\u001b[39m \u001b[33;43m                                    auto tmp8 = decltype(tmp4)(tmp4 * tmp7);\u001b[39;49m\n\u001b[32m    791\u001b[39m \u001b[33;43m                                    tmp_acc0_arr[x0_tail - static_cast<int64_t>(16LL)] = tmp_acc0_arr[x0_tail - static_cast<int64_t>(16LL)] + tmp4;\u001b[39;49m\n\u001b[32m    792\u001b[39m \u001b[33;43m                                    tmp_acc1_arr[x0_tail - static_cast<int64_t>(16LL)] = tmp_acc1_arr[x0_tail - static_cast<int64_t>(16LL)] + tmp8;\u001b[39;49m\n\u001b[32m    793\u001b[39m \u001b[33;43m                                }\u001b[39;49m\n\u001b[32m    794\u001b[39m \u001b[33;43m                            }\u001b[39;49m\n\u001b[32m    795\u001b[39m \u001b[33;43m                        }\u001b[39;49m\n\u001b[32m    796\u001b[39m \u001b[33;43m                    }\u001b[39;49m\n\u001b[32m    797\u001b[39m \u001b[33;43m                    tmp_acc0_vec_arr[tid] = tmp_acc0_vec_local;\u001b[39;49m\n\u001b[32m    798\u001b[39m \u001b[33;43m                    tmp_acc0_arr[tid] = tmp_acc0_local;\u001b[39;49m\n\u001b[32m    799\u001b[39m \u001b[33;43m                    tmp_acc1_vec_arr[tid] = tmp_acc1_vec_local;\u001b[39;49m\n\u001b[32m    800\u001b[39m \u001b[33;43m                    tmp_acc1_arr[tid] = tmp_acc1_local;\u001b[39;49m\n\u001b[32m    801\u001b[39m \u001b[33;43m                }\u001b[39;49m\n\u001b[32m    802\u001b[39m \u001b[33;43m                for (int tid = 0; tid < 8; tid++)\u001b[39;49m\n\u001b[32m    803\u001b[39m \u001b[33;43m                \u001b[39;49m\u001b[33;43m{\u001b[39;49m\n\u001b[32m    804\u001b[39m \u001b[33;43m                    tmp_acc0_vec = tmp_acc0_vec + tmp_acc0_vec_arr[tid];\u001b[39;49m\n\u001b[32m    805\u001b[39m \u001b[33;43m                }\u001b[39;49m\n\u001b[32m    806\u001b[39m \u001b[33;43m                for (int tid = 0; tid < 8; tid++)\u001b[39;49m\n\u001b[32m    807\u001b[39m \u001b[33;43m                \u001b[39;49m\u001b[33;43m{\u001b[39;49m\n\u001b[32m    808\u001b[39m \u001b[33;43m                    tmp_acc0 = tmp_acc0 + tmp_acc0_arr[tid];\u001b[39;49m\n\u001b[32m    809\u001b[39m \u001b[33;43m                }\u001b[39;49m\n\u001b[32m    810\u001b[39m \u001b[33;43m                for (int tid = 0; tid < 8; tid++)\u001b[39;49m\n\u001b[32m    811\u001b[39m \u001b[33;43m                \u001b[39;49m\u001b[33;43m{\u001b[39;49m\n\u001b[32m    812\u001b[39m \u001b[33;43m                    tmp_acc1_vec = tmp_acc1_vec + tmp_acc1_vec_arr[tid];\u001b[39;49m\n\u001b[32m    813\u001b[39m \u001b[33;43m                }\u001b[39;49m\n\u001b[32m    814\u001b[39m \u001b[33;43m                for (int tid = 0; tid < 8; tid++)\u001b[39;49m\n\u001b[32m    815\u001b[39m \u001b[33;43m                \u001b[39;49m\u001b[33;43m{\u001b[39;49m\n\u001b[32m    816\u001b[39m \u001b[33;43m                    tmp_acc1 = tmp_acc1 + tmp_acc1_arr[tid];\u001b[39;49m\n\u001b[32m    817\u001b[39m \u001b[33;43m                }\u001b[39;49m\n\u001b[32m    818\u001b[39m \u001b[33;43m                if(C10_LIKELY(x0 >= static_cast<int64_t>(0) && x0 < static_cast<int64_t>(16LL)))\u001b[39;49m\n\u001b[32m    819\u001b[39m \u001b[33;43m                \u001b[39;49m\u001b[33;43m{\u001b[39;49m\n\u001b[32m    820\u001b[39m \u001b[33;43m                    tmp_acc0_vec.store(out_ptr1 + static_cast<int64_t>(x0));\u001b[39;49m\n\u001b[32m    821\u001b[39m \u001b[33;43m                    tmp_acc1_vec.store(out_ptr2 + static_cast<int64_t>(x0));\u001b[39;49m\n\u001b[32m    822\u001b[39m \u001b[33;43m                }\u001b[39;49m\n\u001b[32m    823\u001b[39m \u001b[33;43m                if(C10_UNLIKELY(x0 >= static_cast<int64_t>(16LL) && x0 < static_cast<int64_t>(25LL)))\u001b[39;49m\n\u001b[32m    824\u001b[39m \u001b[33;43m                \u001b[39;49m\u001b[33;43m{\u001b[39;49m\n\u001b[32m    825\u001b[39m \u001b[33;43m                    for (int64_t x0_tail = static_cast<int64_t>(16LL);x0_tail < static_cast<int64_t>(25LL); x0_tail++)\u001b[39;49m\n\u001b[32m    826\u001b[39m \u001b[33;43m                    \u001b[39;49m\u001b[33;43m{\u001b[39;49m\n\u001b[32m    827\u001b[39m \u001b[33;43m                        out_ptr1[static_cast<int64_t>(x0_tail)] = tmp_acc0_arr[x0_tail - static_cast<int64_t>(16LL)];\u001b[39;49m\n\u001b[32m    828\u001b[39m \u001b[33;43m                        out_ptr2[static_cast<int64_t>(x0_tail)] = tmp_acc1_arr[x0_tail - static_cast<int64_t>(16LL)];\u001b[39;49m\n\u001b[32m    829\u001b[39m \u001b[33;43m                    }\u001b[39;49m\n\u001b[32m    830\u001b[39m \u001b[33;43m                }\u001b[39;49m\n\u001b[32m    831\u001b[39m \u001b[33;43m            }\u001b[39;49m\n\u001b[32m    832\u001b[39m \u001b[33;43m        }\u001b[39;49m\n\u001b[32m    833\u001b[39m \u001b[33;43m    }\u001b[39;49m\n\u001b[32m    834\u001b[39m \u001b[33;43m    \u001b[39;49m\u001b[33;43m{\u001b[39;49m\n\u001b[32m    835\u001b[39m \u001b[33;43m        for(int64_t x0=static_cast<int64_t>(0LL); x0<static_cast<int64_t>(25LL); x0+=static_cast<int64_t>(16LL))\u001b[39;49m\n\u001b[32m    836\u001b[39m \u001b[33;43m        \u001b[39;49m\u001b[33;43m{\u001b[39;49m\n\u001b[32m    837\u001b[39m \u001b[33;43m            \u001b[39;49m\u001b[33;43m{\u001b[39;49m\n\u001b[32m    838\u001b[39m \u001b[33;43m                if(C10_LIKELY(x0 >= static_cast<int64_t>(0) && x0 < static_cast<int64_t>(16LL)))\u001b[39;49m\n\u001b[32m    839\u001b[39m \u001b[33;43m                \u001b[39;49m\u001b[33;43m{\u001b[39;49m\n\u001b[32m    840\u001b[39m \u001b[33;43m                    auto tmp0 = at::vec::Vectorized<float>::loadu(out_ptr2 + static_cast<int64_t>(x0), static_cast<int64_t>(16));\u001b[39;49m\n\u001b[32m    841\u001b[39m \u001b[33;43m                    auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<int64_t>(x0), static_cast<int64_t>(16));\u001b[39;49m\n\u001b[32m    842\u001b[39m \u001b[33;43m                    auto tmp2 = tmp0 * tmp1;\u001b[39;49m\n\u001b[32m    843\u001b[39m \u001b[33;43m                    tmp2.store(out_ptr3 + static_cast<int64_t>(x0));\u001b[39;49m\n\u001b[32m    844\u001b[39m \u001b[33;43m                }\u001b[39;49m\n\u001b[32m    845\u001b[39m \u001b[33;43m                if(C10_UNLIKELY(x0 >= static_cast<int64_t>(16LL) && x0 < static_cast<int64_t>(25LL)))\u001b[39;49m\n\u001b[32m    846\u001b[39m \u001b[33;43m                \u001b[39;49m\u001b[33;43m{\u001b[39;49m\n\u001b[32m    847\u001b[39m \u001b[33;43m                    auto tmp0 = at::vec::Vectorized<float>::loadu(out_ptr2 + static_cast<int64_t>(x0), static_cast<int64_t>(9LL));\u001b[39;49m\n\u001b[32m    848\u001b[39m \u001b[33;43m                    auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<int64_t>(x0), static_cast<int64_t>(9LL));\u001b[39;49m\n\u001b[32m    849\u001b[39m \u001b[33;43m                    auto tmp2 = tmp0 * tmp1;\u001b[39;49m\n\u001b[32m    850\u001b[39m \u001b[33;43m                    tmp2.store(out_ptr3 + static_cast<int64_t>(x0), static_cast<int64_t>(9LL));\u001b[39;49m\n\u001b[32m    851\u001b[39m \u001b[33;43m                }\u001b[39;49m\n\u001b[32m    852\u001b[39m \u001b[33;43m            }\u001b[39;49m\n\u001b[32m    853\u001b[39m \u001b[33;43m        }\u001b[39;49m\n\u001b[32m    854\u001b[39m \u001b[33;43m    }\u001b[39;49m\n\u001b[32m    855\u001b[39m \u001b[33;43m    #pragma omp parallel num_threads(8)\u001b[39;49m\n\u001b[32m    856\u001b[39m \u001b[33;43m    \u001b[39;49m\u001b[33;43m{\u001b[39;49m\n\u001b[32m    857\u001b[39m \u001b[33;43m        int tid = omp_get_thread_num();\u001b[39;49m\n\u001b[32m    858\u001b[39m \u001b[33;43m        \u001b[39;49m\u001b[33;43m{\u001b[39;49m\n\u001b[32m    859\u001b[39m \u001b[33;43m            #pragma omp for\u001b[39;49m\n\u001b[32m    860\u001b[39m \u001b[33;43m            for(int64_t x0=static_cast<int64_t>(0LL); x0<static_cast<int64_t>(25088LL); x0+=static_cast<int64_t>(1LL))\u001b[39;49m\n\u001b[32m    861\u001b[39m \u001b[33;43m            \u001b[39;49m\u001b[33;43m{\u001b[39;49m\n\u001b[32m    862\u001b[39m \u001b[33;43m                for(int64_t x1=static_cast<int64_t>(0LL); x1<static_cast<int64_t>(25LL); x1+=static_cast<int64_t>(16LL))\u001b[39;49m\n\u001b[32m    863\u001b[39m \u001b[33;43m                \u001b[39;49m\u001b[33;43m{\u001b[39;49m\n\u001b[32m    864\u001b[39m \u001b[33;43m                    \u001b[39;49m\u001b[33;43m{\u001b[39;49m\n\u001b[32m    865\u001b[39m \u001b[33;43m                        if(C10_LIKELY(x1 >= static_cast<int64_t>(0) && x1 < static_cast<int64_t>(16LL)))\u001b[39;49m\n\u001b[32m    866\u001b[39m \u001b[33;43m                        \u001b[39;49m\u001b[33;43m{\u001b[39;49m\n\u001b[32m    867\u001b[39m \u001b[33;43m                            auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<int64_t>(x1 + 25LL*x0), static_cast<int64_t>(16));\u001b[39;49m\n\u001b[32m    868\u001b[39m \u001b[33;43m                            auto tmp4 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<int64_t>(x1 + 25LL*x0), static_cast<int64_t>(16));\u001b[39;49m\n\u001b[32m    869\u001b[39m \u001b[33;43m                            auto tmp6 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<int64_t>(x1 + 25LL*x0), static_cast<int64_t>(16));\u001b[39;49m\n\u001b[32m    870\u001b[39m \u001b[33;43m                            auto tmp7 = at::vec::Vectorized<float>::loadu(in_ptr4 + static_cast<int64_t>(x1), static_cast<int64_t>(16));\u001b[39;49m\n\u001b[32m    871\u001b[39m \u001b[33;43m                            auto tmp9 = at::vec::Vectorized<float>::loadu(out_ptr2 + static_cast<int64_t>(x1), static_cast<int64_t>(16));\u001b[39;49m\n\u001b[32m    872\u001b[39m \u001b[33;43m                            auto tmp13 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<int64_t>(x1), static_cast<int64_t>(16));\u001b[39;49m\n\u001b[32m    873\u001b[39m \u001b[33;43m                            auto tmp18 = at::vec::Vectorized<float>::loadu(out_ptr1 + static_cast<int64_t>(x1), static_cast<int64_t>(16));\u001b[39;49m\n\u001b[32m    874\u001b[39m \u001b[33;43m                            auto tmp21 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<int64_t>(x1), static_cast<int64_t>(16));\u001b[39;49m\n\u001b[32m    875\u001b[39m \u001b[33;43m                            auto tmp1 = static_cast<float>(0.0);\u001b[39;49m\n\u001b[32m    876\u001b[39m \u001b[33;43m                            auto tmp2 = at::vec::Vectorized<float>(tmp1);\u001b[39;49m\n\u001b[32m    877\u001b[39m \u001b[33;43m                            auto tmp3 = at::vec::VecMask<float,1>(tmp0 <= tmp2);\u001b[39;49m\n\u001b[32m    878\u001b[39m \u001b[33;43m                            auto tmp5 = decltype(tmp2)::blendv(tmp4, tmp2, tmp3.template cast<float,1>());\u001b[39;49m\n\u001b[32m    879\u001b[39m \u001b[33;43m                            auto tmp8 = tmp6 - tmp7;\u001b[39;49m\n\u001b[32m    880\u001b[39m \u001b[33;43m                            auto tmp10 = static_cast<float>(3.985969387755102e-05);\u001b[39;49m\n\u001b[32m    881\u001b[39m \u001b[33;43m                            auto tmp11 = at::vec::Vectorized<float>(tmp10);\u001b[39;49m\n\u001b[32m    882\u001b[39m \u001b[33;43m                            auto tmp12 = tmp9 * tmp11;\u001b[39;49m\n\u001b[32m    883\u001b[39m \u001b[33;43m                            auto tmp14 = tmp13 * tmp13;\u001b[39;49m\n\u001b[32m    884\u001b[39m \u001b[33;43m                            auto tmp15 = tmp12 * tmp14;\u001b[39;49m\n\u001b[32m    885\u001b[39m \u001b[33;43m                            auto tmp16 = tmp8 * tmp15;\u001b[39;49m\n\u001b[32m    886\u001b[39m \u001b[33;43m                            auto tmp17 = tmp5 - tmp16;\u001b[39;49m\n\u001b[32m    887\u001b[39m \u001b[33;43m                            auto tmp19 = tmp18 * tmp11;\u001b[39;49m\n\u001b[32m    888\u001b[39m \u001b[33;43m                            auto tmp20 = tmp17 - tmp19;\u001b[39;49m\n\u001b[32m    889\u001b[39m \u001b[33;43m                            auto tmp22 = tmp13 * tmp21;\u001b[39;49m\n\u001b[32m    890\u001b[39m \u001b[33;43m                            auto tmp23 = tmp20 * tmp22;\u001b[39;49m\n\u001b[32m    891\u001b[39m \u001b[33;43m                            tmp23.store(in_out_ptr0 + static_cast<int64_t>(x1 + 25LL*x0));\u001b[39;49m\n\u001b[32m    892\u001b[39m \u001b[33;43m                        }\u001b[39;49m\n\u001b[32m    893\u001b[39m \u001b[33;43m                        if(C10_UNLIKELY(x1 >= static_cast<int64_t>(16LL) && x1 < static_cast<int64_t>(25LL)))\u001b[39;49m\n\u001b[32m    894\u001b[39m \u001b[33;43m                        \u001b[39;49m\u001b[33;43m{\u001b[39;49m\n\u001b[32m    895\u001b[39m \u001b[33;43m                            for (int64_t x1_tail = static_cast<int64_t>(16LL);x1_tail < static_cast<int64_t>(25LL); x1_tail++)\u001b[39;49m\n\u001b[32m    896\u001b[39m \u001b[33;43m                            \u001b[39;49m\u001b[33;43m{\u001b[39;49m\n\u001b[32m    897\u001b[39m \u001b[33;43m                                auto tmp0 = in_out_ptr0[static_cast<int64_t>(x1_tail + 25LL*x0)];\u001b[39;49m\n\u001b[32m    898\u001b[39m \u001b[33;43m                                auto tmp3 = out_ptr0[static_cast<int64_t>(x1_tail + 25LL*x0)];\u001b[39;49m\n\u001b[32m    899\u001b[39m \u001b[33;43m                                auto tmp5 = in_ptr3[static_cast<int64_t>(x1_tail + 25LL*x0)];\u001b[39;49m\n\u001b[32m    900\u001b[39m \u001b[33;43m                                auto tmp6 = in_ptr4[static_cast<int64_t>(x1_tail)];\u001b[39;49m\n\u001b[32m    901\u001b[39m \u001b[33;43m                                auto tmp8 = out_ptr2[static_cast<int64_t>(x1_tail)];\u001b[39;49m\n\u001b[32m    902\u001b[39m \u001b[33;43m                                auto tmp11 = in_ptr5[static_cast<int64_t>(x1_tail)];\u001b[39;49m\n\u001b[32m    903\u001b[39m \u001b[33;43m                                auto tmp16 = out_ptr1[static_cast<int64_t>(x1_tail)];\u001b[39;49m\n\u001b[32m    904\u001b[39m \u001b[33;43m                                auto tmp19 = in_ptr6[static_cast<int64_t>(x1_tail)];\u001b[39;49m\n\u001b[32m    905\u001b[39m \u001b[33;43m                                auto tmp1 = static_cast<float>(0.0);\u001b[39;49m\n\u001b[32m    906\u001b[39m \u001b[33;43m                                auto tmp2 = tmp0 <= tmp1;\u001b[39;49m\n\u001b[32m    907\u001b[39m \u001b[33;43m                                auto tmp4 = tmp2 ? tmp1 : tmp3;\u001b[39;49m\n\u001b[32m    908\u001b[39m \u001b[33;43m                                auto tmp7 = decltype(tmp5)(tmp5 - tmp6);\u001b[39;49m\n\u001b[32m    909\u001b[39m \u001b[33;43m                                auto tmp9 = static_cast<float>(3.985969387755102e-05);\u001b[39;49m\n\u001b[32m    910\u001b[39m \u001b[33;43m                                auto tmp10 = decltype(tmp8)(tmp8 * tmp9);\u001b[39;49m\n\u001b[32m    911\u001b[39m \u001b[33;43m                                auto tmp12 = decltype(tmp11)(tmp11 * tmp11);\u001b[39;49m\n\u001b[32m    912\u001b[39m \u001b[33;43m                                auto tmp13 = decltype(tmp10)(tmp10 * tmp12);\u001b[39;49m\n\u001b[32m    913\u001b[39m \u001b[33;43m                                auto tmp14 = decltype(tmp7)(tmp7 * tmp13);\u001b[39;49m\n\u001b[32m    914\u001b[39m \u001b[33;43m                                auto tmp15 = decltype(tmp4)(tmp4 - tmp14);\u001b[39;49m\n\u001b[32m    915\u001b[39m \u001b[33;43m                                auto tmp17 = decltype(tmp16)(tmp16 * tmp9);\u001b[39;49m\n\u001b[32m    916\u001b[39m \u001b[33;43m                                auto tmp18 = decltype(tmp15)(tmp15 - tmp17);\u001b[39;49m\n\u001b[32m    917\u001b[39m \u001b[33;43m                                auto tmp20 = decltype(tmp11)(tmp11 * tmp19);\u001b[39;49m\n\u001b[32m    918\u001b[39m \u001b[33;43m                                auto tmp21 = decltype(tmp18)(tmp18 * tmp20);\u001b[39;49m\n\u001b[32m    919\u001b[39m \u001b[33;43m                                in_out_ptr0[static_cast<int64_t>(x1_tail + 25LL*x0)] = tmp21;\u001b[39;49m\n\u001b[32m    920\u001b[39m \u001b[33;43m                            }\u001b[39;49m\n\u001b[32m    921\u001b[39m \u001b[33;43m                        }\u001b[39;49m\n\u001b[32m    922\u001b[39m \u001b[33;43m                    }\u001b[39;49m\n\u001b[32m    923\u001b[39m \u001b[33;43m                }\u001b[39;49m\n\u001b[32m    924\u001b[39m \u001b[33;43m            }\u001b[39;49m\n\u001b[32m    925\u001b[39m \u001b[33;43m        }\u001b[39;49m\n\u001b[32m    926\u001b[39m \u001b[33;43m    }\u001b[39;49m\n\u001b[32m    927\u001b[39m \u001b[33;43m}\u001b[39;49m\n\u001b[32m    928\u001b[39m \u001b[33;43m'''\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    931\u001b[39m cpp_fused_sum_4 = async_compile.cpp_pybinding([\u001b[33m'\u001b[39m\u001b[33mconst float*\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mconst float*\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mfloat*\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mfloat*\u001b[39m\u001b[33m'\u001b[39m], \u001b[33m'''\u001b[39m\n\u001b[32m    932\u001b[39m \u001b[33m#include \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mC:/Users/grsim/AppData/Local/Temp/torchinductor_grsim/pi/cpicxudqmdsjh5cm4klbtbrvy2cxwr7whxl3md2zzdjdf3orvfdf.h\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    933\u001b[39m \u001b[33mextern \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mC\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m __declspec(dllexport) void kernel(const float* in_ptr0,\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    993\u001b[39m \u001b[33m}\u001b[39m\n\u001b[32m    994\u001b[39m \u001b[33m'''\u001b[39m)\n\u001b[32m    997\u001b[39m async_compile.wait(\u001b[38;5;28mglobals\u001b[39m())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\_inductor\\async_compile.py:370\u001b[39m, in \u001b[36mAsyncCompile.cpp_pybinding\u001b[39m\u001b[34m(self, argtypes, source_code)\u001b[39m\n\u001b[32m    368\u001b[39m kernel_code_log.info(\u001b[33m\"\u001b[39m\u001b[33mCPP+Bindings Kernel:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, source_code)\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m get_compile_threads() <= \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m370\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mCppPythonBindingsCodeCache\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_pybinding\u001b[49m\u001b[43m(\u001b[49m\u001b[43margtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource_code\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    372\u001b[39m     get_result = CppPythonBindingsCodeCache.load_pybinding_async(\n\u001b[32m    373\u001b[39m         argtypes, source_code, submit_fn=\u001b[38;5;28mself\u001b[39m.submit\n\u001b[32m    374\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\_inductor\\codecache.py:2250\u001b[39m, in \u001b[36mCppPythonBindingsCodeCache.load_pybinding\u001b[39m\u001b[34m(cls, *args, **kwargs)\u001b[39m\n\u001b[32m   2248\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m   2249\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_pybinding\u001b[39m(\u001b[38;5;28mcls\u001b[39m, *args: Any, **kwargs: Any) -> Any:\n\u001b[32m-> \u001b[39m\u001b[32m2250\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mload_pybinding_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\_inductor\\codecache.py:2242\u001b[39m, in \u001b[36mCppPythonBindingsCodeCache.load_pybinding_async.<locals>.future\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   2240\u001b[39m \u001b[38;5;28;01mnonlocal\u001b[39;00m result\n\u001b[32m   2241\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2242\u001b[39m     result = \u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2243\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, ModuleType)\n\u001b[32m   2244\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(result, \u001b[38;5;28mcls\u001b[39m.entry_function)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\_inductor\\codecache.py:2051\u001b[39m, in \u001b[36mCppCodeCache.load_async.<locals>.load_fn\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   2049\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m future \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2050\u001b[39m     future.result()\n\u001b[32m-> \u001b[39m\u001b[32m2051\u001b[39m result = \u001b[43mworker_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2052\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2053\u001b[39m lib = \u001b[38;5;28mcls\u001b[39m._load_library(binary_path, key)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\_inductor\\codecache.py:2079\u001b[39m, in \u001b[36m_worker_compile_cpp\u001b[39m\u001b[34m(lock_path, cpp_builder)\u001b[39m\n\u001b[32m   2077\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m FileLock(lock_path, timeout=LOCK_TIMEOUT):\n\u001b[32m   2078\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(cpp_builder.get_target_file_path()):\n\u001b[32m-> \u001b[39m\u001b[32m2079\u001b[39m         \u001b[43mcpp_builder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\_inductor\\cpp_builder.py:1601\u001b[39m, in \u001b[36mCppBuilder.build\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1598\u001b[39m _create_if_dir_not_exist(_build_tmp_dir)\n\u001b[32m   1600\u001b[39m build_cmd = \u001b[38;5;28mself\u001b[39m.get_command_line()\n\u001b[32m-> \u001b[39m\u001b[32m1601\u001b[39m \u001b[43mrun_compile_cmd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuild_cmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_build_tmp_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1602\u001b[39m _remove_dir(_build_tmp_dir)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\_inductor\\cpp_builder.py:355\u001b[39m, in \u001b[36mrun_compile_cmd\u001b[39m\u001b[34m(cmd_line, cwd)\u001b[39m\n\u001b[32m    353\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_compile_cmd\u001b[39m(cmd_line: \u001b[38;5;28mstr\u001b[39m, cwd: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    354\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m dynamo_timed(\u001b[33m\"\u001b[39m\u001b[33mcompile_file\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m         \u001b[43m_run_compile_cmd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd_line\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\_inductor\\cpp_builder.py:350\u001b[39m, in \u001b[36m_run_compile_cmd\u001b[39m\u001b[34m(cmd_line, cwd)\u001b[39m\n\u001b[32m    340\u001b[39m     instruction = (\n\u001b[32m    341\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mOpenMP support not found. Please try one of the following solutions:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    342\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m(1) Set the `CXX` environment variable to a compiler other than Apple clang++/g++ \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    347\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m with `include/omp.h` under it.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    348\u001b[39m     )\n\u001b[32m    349\u001b[39m     output += instruction\n\u001b[32m--> \u001b[39m\u001b[32m350\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc.CppCompileError(cmd, output) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mInductorError\u001b[39m: CppCompileError: C++ compile error\n\nCommand:\ncl /I C:/Program Files/WindowsApps/PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0/Include /I C:/Users/grsim/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0/LocalCache/local-packages/Python313/site-packages/torch/include /I C:/Users/grsim/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0/LocalCache/local-packages/Python313/site-packages/torch/include/torch/csrc/api/include /D TORCH_INDUCTOR_CPP_WRAPPER /D STANDALONE_TORCH_HEADER /D C10_USING_CUSTOM_GENERATED_MACROS /D CPU_CAPABILITY_AVX512 /DLL /MD /O2 /std:c++20 /wd4819 /wd4251 /wd4244 /wd4267 /wd4275 /wd4018 /wd4190 /wd4624 /wd4067 /wd4068 /EHsc /openmp /openmp:experimental C:/Users/grsim/AppData/Local/Temp/torchinductor_grsim/6g/c6gvgbhhmkzfnqez7el2fznzmlioke25zdsdxtrovbbklpyac7lg.cpp /arch:AVX512 /LD /FeC:/Users/grsim/AppData/Local/Temp/torchinductor_grsim/6g/c6gvgbhhmkzfnqez7el2fznzmlioke25zdsdxtrovbbklpyac7lg.pyd /link /LIBPATH:C:/Program Files/WindowsApps/PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0/libs /LIBPATH:C:/Users/grsim/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0/LocalCache/local-packages/Python313/site-packages/torch/lib torch.lib torch_cpu.lib torch_python.lib sleef.lib\n\nOutput:\nMicrosoft (R) C/C++ Optimizing Compiler Version 19.43.34810 for x64\r\nCopyright (C) Microsoft Corporation.  All rights reserved.\r\n\r\ncl : Command line warning D9025 : overriding '/openmp' with '/openmp:experimental'\r\nc6gvgbhhmkzfnqez7el2fznzmlioke25zdsdxtrovbbklpyac7lg.cpp\r\nC:/Users/grsim/AppData/Local/Temp/torchinductor_grsim/6g/c6gvgbhhmkzfnqez7el2fznzmlioke25zdsdxtrovbbklpyac7lg.cpp(121): error C2374: 'tmp_acc0_arr': redefinition; multiple initialization\r\nC:/Users/grsim/AppData/Local/Temp/torchinductor_grsim/6g/c6gvgbhhmkzfnqez7el2fznzmlioke25zdsdxtrovbbklpyac7lg.cpp(102): note: see declaration of 'tmp_acc0_arr'\r\nC:/Users/grsim/AppData/Local/Temp/torchinductor_grsim/6g/c6gvgbhhmkzfnqez7el2fznzmlioke25zdsdxtrovbbklpyac7lg.cpp(121): error C2086: 'std::unique_ptr<float [],std::default_delete<float []>> tmp_acc0_arr': redefinition\r\nC:/Users/grsim/AppData/Local/Temp/torchinductor_grsim/6g/c6gvgbhhmkzfnqez7el2fznzmlioke25zdsdxtrovbbklpyac7lg.cpp(102): note: see declaration of 'tmp_acc0_arr'\r\nC:/Users/grsim/AppData/Local/Temp/torchinductor_grsim/6g/c6gvgbhhmkzfnqez7el2fznzmlioke25zdsdxtrovbbklpyac7lg.cpp(121): error C2371: 'tmp_acc0_arr': redefinition; different basic types\r\nC:/Users/grsim/AppData/Local/Temp/torchinductor_grsim/6g/c6gvgbhhmkzfnqez7el2fznzmlioke25zdsdxtrovbbklpyac7lg.cpp(131): error C2374: 'tmp_acc1_arr': redefinition; multiple initialization\r\nC:/Users/grsim/AppData/Local/Temp/torchinductor_grsim/6g/c6gvgbhhmkzfnqez7el2fznzmlioke25zdsdxtrovbbklpyac7lg.cpp(107): note: see declaration of 'tmp_acc1_arr'\r\nC:/Users/grsim/AppData/Local/Temp/torchinductor_grsim/6g/c6gvgbhhmkzfnqez7el2fznzmlioke25zdsdxtrovbbklpyac7lg.cpp(131): error C2086: 'std::unique_ptr<float [],std::default_delete<float []>> tmp_acc1_arr': redefinition\r\nC:/Users/grsim/AppData/Local/Temp/torchinductor_grsim/6g/c6gvgbhhmkzfnqez7el2fznzmlioke25zdsdxtrovbbklpyac7lg.cpp(107): note: see declaration of 'tmp_acc1_arr'\r\nC:/Users/grsim/AppData/Local/Temp/torchinductor_grsim/6g/c6gvgbhhmkzfnqez7el2fznzmlioke25zdsdxtrovbbklpyac7lg.cpp(131): error C2371: 'tmp_acc1_arr': redefinition; different basic types\r\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print('Epoch: {}'.format(epoch))\n",
    "    train()\n",
    "    validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pVytGlnl3ZZR"
   },
   "source": [
    "### 3.5.1 Discussion of Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ukd8Kk8l3ZZR"
   },
   "source": [
    "It looks like this model is significantly improved! The training accuracy is very high, and the validation accuracy has improved as well. This is a great result, as all we had to do was swap in a new model.\n",
    "\n",
    "You may have noticed the validation accuracy jumping around. This is an indication that our model is still not generalizing perfectly. Fortunately, there's more that we can do. Let's talk about it in the next lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zsOHIy5F3ZZR"
   },
   "source": [
    "## 3.6 Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DcIRdSur3ZZR"
   },
   "source": [
    "In this section, we utilized several new kinds of layers to implement a CNN, which performed better than the more simple model used in the last section. Hopefully the overall process of creating and training a model with prepared data is starting to become even more familiar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o0wFCmbK3ZZS"
   },
   "source": [
    "### 3.6.1 Clear the Memory\n",
    "Before moving on, please execute the following cell to clear up the GPU memory. This is required to move on to the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Ul7wgax3ZZS"
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4kMR2FOK3ZZS"
   },
   "source": [
    "### 3.6.2 Next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "13FglbMX3ZZS"
   },
   "source": [
    "In the last several sections you have focused on the creation and training of models. In order to further improve performance, you will now turn your attention to *data augmentation*, a collection of techniques that will allow your models to train on more and better data than what you might have originally at your disposal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PEzcSC6x3ZZS"
   },
   "source": [
    "<center><a href=\"https://www.nvidia.com/dli\"> <img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a></center>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
